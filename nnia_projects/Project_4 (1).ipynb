{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project_4.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "-bfESCtCZDjO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# NNIA 18/19 Project 4:  Optimization \\& Recurrent Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "iSDvzfNmZDjW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Deadline: 28. Februrary 2019, 23:59"
      ]
    },
    {
      "metadata": {
        "id": "Ml8ojf7TvLqi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hanvU4nTZDjb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# imports\n",
        "%matplotlib notebook\n",
        "import re\n",
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib as mpl\n",
        "from matplotlib import cm\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.contrib import rnn\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "mpl.rcParams['figure.figsize'] = (12.0, 8.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTa5L_xsZDjs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Optimization Algorithms$~$ (6 points)"
      ]
    },
    {
      "metadata": {
        "id": "sr70CW2vZDjz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In this task, we will get familiar with various optimization methods such as **Vanilla Gradient Descent** (GD), [**Gradient Descent with Momentum**](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer), [**RMSProp**](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer) and [**AdaGrad**](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer) by implementing them in TensorFlow and *visualizing* the path (convergence) towards minima using [Matplotlib 3D/Contour plots](https://matplotlib.org/mpl_toolkits/mplot3d/tutorial.html)."
      ]
    },
    {
      "metadata": {
        "id": "4Ewt92noZDj2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**3D Loss Surface**\n",
        "\n",
        "For the following exercises we assume that the surface of the general **loss** we want to minimize is given by a function `z`. On this function, we apply different optimization methods and want to visualize their stepwise improvements. `z` is defined as:\n",
        "\n",
        "$$ term1 = \\frac{2}{\\sqrt{(2\\pi \\alpha_{1}^{2})^{2}}} * \\exp{\\left(- \\left[ \\frac{(x-\\mu_1)^2}{(\\frac{\\alpha {1}}{2})^2} + \\frac{(y-\\mu_1)^2}{(\\alpha_1)^2}     \\right] \\right)} $$\n",
        "\n",
        "$$ term2 = \\frac{1}{\\sqrt{(2\\pi \\alpha_{2}^{2})^{2}}} * \\exp{\\left(- \\left[ \\frac{(x-\\mu_2)^2 + (y-\\mu_2)^2}{(\\alpha_2)^2} \\right] \\right)} $$\n",
        "\n",
        "$$ term3 = \\frac{1}{20} * \\left(x^2  + xy + y^2 \\right) $$ <br>\n",
        "\n",
        "$$ z_{\\alpha, \\mu}(x, y) = term1 - term2 + term3 $$"
      ]
    },
    {
      "metadata": {
        "id": "l25CsT5xZDj4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "To make yourself comfortable working with this function we provide a visualization by plotting it in 3D using [matplotlib-3D-wireframe](https://matplotlib.org/devdocs/gallery/mplot3d/wire3d.html). You can interactivaley play around with the plot to get familiar with the surface."
      ]
    },
    {
      "metadata": {
        "id": "asFTalJzZDj-",
        "colab_type": "code",
        "outputId": "ac9ccccd-5b5a-40ee-a8d7-3dc41a8bc9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "# %matplotlib inline\n",
        "\n",
        "# params of our error surface `z`\n",
        "alpha_1 = 1.0\n",
        "alpha_2 = 2.0\n",
        "mu_1 = 0.5\n",
        "mu_2 = 0.0\n",
        "range_x, range_y = np.arange(-2.0, 3.0, 0.5), np.arange(-2.0, 2.0, 0.5)\n",
        "\n",
        "def func_z(X, Y):\n",
        "    \"\"\"\n",
        "    function definition of our 3D error surface\n",
        "    \"\"\"\n",
        "    exp_input_1 = -1 * ((((X - mu_1)**2) / (alpha_1/2)**2) + (((Y - mu_1)**2)/(alpha_1**2)))\n",
        "    term_1 = 2/np.sqrt((2 * np.pi * alpha_1**2)**2) * np.exp(exp_input_1)\n",
        "    \n",
        "    exp_input_2 = -1 * ( ((X - mu_2)**2 + (Y - mu_2)**2) / alpha_2**2)\n",
        "    term_2 = 1/np.sqrt((2 * np.pi * alpha_2**2)**2) * np.exp(exp_input_2)\n",
        "    \n",
        "    term_3 = 1/20 * (X**2 + X * Y + Y**2)\n",
        "    \n",
        "    return term_1 - term_2 + term_3\n",
        "\n",
        "# x,y values for `Wireframe` plot\n",
        "x_wireframe, y_wireframe = np.arange(-2.0, 3.0, 0.5), np.arange(-2.0, 2.0, 0.5)\n",
        "\n",
        "# x,y values for `Contour` plot\n",
        "x_contour, y_contour = np.arange(-2.0, 3.0, 0.1), np.arange(-2.0, 2.0, 0.1)\n",
        "\n",
        "# Following code implements the plotting the Error Surface\n",
        "X_sparse, Y_sparse = np.meshgrid(x_wireframe, y_wireframe)\n",
        "Z_sparse = func_z(X_sparse, Y_sparse)\n",
        "\n",
        "X_dense, Y_dense = np.meshgrid(x_contour, y_contour)\n",
        "Z_dense = func_z(X_dense, Y_dense)\n",
        "\n",
        "fig = plt.figure(figsize=(9,4))\n",
        "ax1 = fig.add_subplot(121,projection='3d')\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "ax1.plot_wireframe(X_sparse, Y_sparse, Z_sparse, linewidth=1, cmap=cm.jet, zorder=1, alpha=0.6)\n",
        "ax2.contour(X_dense, Y_dense, Z_dense, 32,  cmap=cm.jet)\n",
        "\n",
        "ax1.set_xlabel(r'$x$',fontsize=18)\n",
        "ax1.set_ylabel(r'$y$',fontsize=18)\n",
        "ax1.set_zlabel(r'$z$',fontsize=18)\n",
        "ax1.set_title('3D Surface', fontsize=18)\n",
        "\n",
        "ax2.contour(X_dense, Y_dense, Z_dense, 32,  cmap=cm.jet)\n",
        "ax2.autoscale(False)\n",
        "ax2.set_title('Contour plot', fontsize=18)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support.' +\n",
              "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>')\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option)\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width, fig.canvas.height);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>')\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        event.shiftKey = false;\n",
              "        // Send a \"J\" for go to next cell\n",
              "        event.which = 74;\n",
              "        event.keyCode = 74;\n",
              "        manager.command_mode();\n",
              "        manager.handle_keydown(event);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='1081d40a-d698-410f-b6d3-ec3368f0cdb1'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "yZzAJyqRZDkH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.1 Error Implementation with Tensorflow"
      ]
    },
    {
      "metadata": {
        "id": "LUNFC1hCZDkK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually, we minimize the loss function of a neural network which is defined by a tensorflow computational graph which allows us perform optimization easily. Here, we first need to implement the 3D surface of the loss function described above using tensorflow. \n",
        "\n",
        "Setup the graph of the function by implementing `problem_3d` using tensorflow operations and variables. Write your code as specified by `# TODO`. (**1 point**)"
      ]
    },
    {
      "metadata": {
        "id": "N8bK-D6-ZDkR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The following variables  will come in handy when implementing the error surface using tensorflow functions below\n",
        "tf_x, tf_y, tf_z, = None, None, None\n",
        "tf_reinit_x, tf_reinit_y = None, None\n",
        "session = None\n",
        "\n",
        "def problem_3d(start_x, start_y):\n",
        "    global session\n",
        "    global tf_x, tf_y, tf_z\n",
        "    global tf_reinit_x, tf_reinit_y\n",
        "    \n",
        "    tf.reset_default_graph()\n",
        "    session = tf.InteractiveSession()\n",
        "\n",
        "    with tf.variable_scope('opt'):\n",
        "        tf_x = tf.get_variable('x', initializer=tf.constant(start_x, shape=None, dtype=tf.float32))\n",
        "        tf_y = tf.get_variable('y', initializer=tf.constant(start_y, shape=None, dtype=tf.float32))\n",
        "\n",
        "    with tf.variable_scope('opt', reuse=True):\n",
        "        tf_reinit_x = tf.assign(tf.get_variable('x'), start_x)\n",
        "        tf_reinit_y = tf.assign(tf.get_variable('y'), start_y)\n",
        "    \n",
        "    # TODO Implement 3D error surface using the above defined variables\n",
        "    exp_input_1 = -1 * ((((tf_x - mu_1)**2) / (alpha_1/2)**2) + (((tf_y - mu_1)**2)/(alpha_1**2)))\n",
        "    tf_term_1 = 2/np.sqrt((2 * np.pi * alpha_1**2)**2) * tf.math.exp(exp_input_1)\n",
        "    \n",
        "    exp_input_2 = -1 * ( ((tf_x - mu_2)**2 + (tf_y - mu_2)**2) / alpha_2**2)\n",
        "    \n",
        "    tf_term_2 = 1/np.sqrt((2 * np.pi * alpha_2**2)**2) * tf.math.exp(exp_input_2)\n",
        "    \n",
        "    tf_term_3 = 1/20 * (tf_x**2 + tf_x * tf_y + tf_y**2)\n",
        "    \n",
        "    \n",
        "    tf_z = tf_term_1 - tf_term_2 + tf_term_3\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z_JuNVc-ZDkd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $1$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "KSdaZ5y8ZDkf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.2 Implementation of Gradient Descent with Momentum\n",
        "\n",
        "In the lecture chapter 8 on slide 20 you got introduced to an advanced implementation of the Gradient Descent Optimizer, called Gradient Descent with Momentum. In this exercise you should implement Gradient Descent with Momentum using tensorflow operations. \n",
        "\n",
        "In the following, we provide a class for GD with Momentum where you have to fill in the `#TODO` sections only. To get gradients of the objective you want to minimize, use the function [`tf.gradients`](https://www.tensorflow.org/api_docs/python/tf/gradients). Make sure, that your variables are always shaped correctly! (**2 points**)."
      ]
    },
    {
      "metadata": {
        "id": "zGwNYBVkZDkj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class GradientDescentMomentumOptimizer():\n",
        "    \n",
        "    def __init__(self, learning_rate, alpha):\n",
        "\n",
        "        with tf.variable_scope('gdm_opt'):\n",
        "            self.learning_rate = tf.get_variable('lr', initializer=tf.constant(learning_rate, shape=[], dtype=tf.float32))\n",
        "            self.alpha = tf.get_variable('alpha', initializer=tf.constant(alpha, shape=None, dtype=tf.float32))\n",
        "            self.v = tf.get_variable('v', initializer=tf.constant([0, 0], shape=[2, 1], dtype=tf.float32))\n",
        "\n",
        "        # input \n",
        "        self.input_x = tf.placeholder(\"float\", [])\n",
        "        self.input_y = tf.placeholder(\"float\", [])\n",
        "\n",
        "        # optimized outputs\n",
        "        self.out_x = None\n",
        "        self.out_y = None  \n",
        "\n",
        "        # gradients\n",
        "        self.grads = None\n",
        "\n",
        "        # objective to minimize      \n",
        "        self.objective = None\n",
        "        \n",
        "    def minimize(self, objective):\n",
        "        self.objective = objective\n",
        "        return self.optimization_step()\n",
        "\n",
        "    def update(self, new_x, new_y, new_v):\n",
        "\n",
        "        with tf.variable_scope('opt', reuse=True):\n",
        "            tf_reinit_x = tf.assign(tf.get_variable('x'), new_x[0])\n",
        "            tf_reinit_y = tf.assign(tf.get_variable('y'), new_y[0])\n",
        "           # print(new_x,'newwwww',new_y)\n",
        "\n",
        "        with tf.variable_scope('gdm_opt', reuse=True):\n",
        "            set_v =  tf.assign(tf.get_variable('v'), new_v)\n",
        "            \n",
        "        return tf_reinit_x, tf_reinit_y, set_v\n",
        "\n",
        "    def optimization_step(self):\n",
        "        \n",
        "        global tf_x, tf_y\n",
        "        \n",
        "        \n",
        "        # TODO: Implement this function returning the updated positions into self.out_x, self.out_y\n",
        "\n",
        "        self.grads = tf.gradients(tf_z,[tf_x,tf_y],stop_gradients=[tf_x,tf_y]) \n",
        "        self.grads = tf.reshape(self.grads, [2,1])\n",
        "        self.v = (self.alpha * self.v) - self.learning_rate * self.grads\n",
        "        self.out_x = tf_x + self.v[0]\n",
        "        self.out_y = tf_y + self.v[1]\n",
        "\n",
        "        return self.out_x, self.out_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hj1NXwtzZDku",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In the following, use your implementation to find a local minimum in our loss function. We choose a fixed starting position and run the optimizer for a certain amount of steps."
      ]
    },
    {
      "metadata": {
        "id": "Pp7d5fPhZDkx",
        "colab_type": "code",
        "outputId": "152882cb-45eb-44dc-ecda-68350cfc0b61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# starting position\n",
        "start_x, start_y = 0.55, 0.6\n",
        "n_steps = 60\n",
        "\n",
        "problem_3d(start_x,start_y)\n",
        "\n",
        "lr = 0.2\n",
        "alpha = 0.9\n",
        "\n",
        "optimizer = GradientDescentMomentumOptimizer(lr, alpha)\n",
        "opt_step = optimizer.minimize(objective=tf_z)\n",
        "\n",
        "# initialize variables\n",
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "# set initial values\n",
        "session.run([tf_reinit_x, tf_reinit_y])\n",
        "\n",
        "# keep track of all steps\n",
        "opt_gd_points_x, opt_gd_points_y, opt_gd_points_z = [],[],[]\n",
        "\n",
        "# fill in the initial position\n",
        "opt_gd_points_x.append(start_x)\n",
        "opt_gd_points_y.append(start_y)\n",
        "opt_gd_points_z.append(func_z(start_x,start_y))\n",
        "\n",
        "x, y = [start_x], [start_y]\n",
        "\n",
        "print(x)\n",
        "print(y)\n",
        "\n",
        "print('Momentum GD Optimization started')\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "for step in range(n_steps):\n",
        "\n",
        "    # perform optimization step\n",
        "    x, y, z, v, cur_gradient, _ = session.run([optimizer.out_x, optimizer.out_y, tf_z, optimizer.v, optimizer.grads, opt_step], feed_dict={optimizer.input_x: x[0], optimizer.input_y: y[0]}) \n",
        "    # update the function\n",
        "    session.run([optimizer.update(x, y, v)])\n",
        "    \n",
        "    opt_gd_points_x.append(x[0])\n",
        "    opt_gd_points_y.append(y[0])\n",
        "    opt_gd_points_z.append(func_z(x[0], y[0]))\n",
        "    \n",
        "    if step % 10 == 0:\n",
        "        print(\"Optimization step {} - minimized value: {}\".format(step, z))\n",
        "        \n",
        "done = time.time()\n",
        "elapsed = done - start\n",
        "print(elapsed)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "[0.55]\n",
            "[0.6]\n",
            "Momentum GD Optimization started\n",
            "Optimization step 0 - minimized value: 0.32791638374328613\n",
            "Optimization step 10 - minimized value: 0.1342935860157013\n",
            "Optimization step 20 - minimized value: 0.045574840158224106\n",
            "Optimization step 30 - minimized value: 0.03934767097234726\n",
            "Optimization step 40 - minimized value: -0.0014221835881471634\n",
            "Optimization step 50 - minimized value: -0.022050585597753525\n",
            "0.888592004776001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "41QipUDTZDk9",
        "colab_type": "code",
        "outputId": "ecb51bb7-efa8-4edd-eb17-b14a83134948",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "cell_type": "code",
      "source": [
        "range_x,range_y = np.arange(-1.0,2.0,0.2), np.arange(-2.0,2.0,0.2)\n",
        "X_lowres, Y_lowres = np.meshgrid(range_x, range_y)\n",
        "Z_lowres = func_z(X_lowres,Y_lowres)\n",
        "\n",
        "range_x,range_y = np.arange(-1.0,2.0,0.1), np.arange(-2.0,2.0,0.1)\n",
        "X_hires, Y_hires = np.meshgrid(range_x, range_y)\n",
        "Z_hires = func_z(X_hires,Y_hires)\n",
        "\n",
        "fig = plt.figure(figsize=(9,4))\n",
        "\n",
        "epsilon = 0.0\n",
        "ax1 = fig.add_subplot(121,projection='3d')\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "# plot\n",
        "ax1.plot_wireframe(X_lowres, Y_lowres, Z_lowres, linewidth=1, cmap=cm.jet, zorder=1, alpha=0.6)\n",
        "ax2.contour(X_hires, Y_hires, Z_hires, 32,  cmap=cm.jet)\n",
        "ax2.autoscale(False)\n",
        "\n",
        "for idx, (x,y,z) in enumerate(zip(opt_gd_points_x, opt_gd_points_y, opt_gd_points_z)):\n",
        "    if idx != len(opt_gd_points_x)-1:\n",
        "        ax1.scatter(x,y,z + epsilon , color='blue', alpha=(idx+10)/(n_steps+10.0), zorder=100)\n",
        "        ax2.scatter(np.asarray(x),np.asarray(y) , color='blue')\n",
        "    else:\n",
        "        ax1.scatter(x,y,z + epsilon , color='blue', alpha=(idx+10)/(n_steps+10.0), label='GD with Momentum', zorder=100)\n",
        "        ax2.scatter(x,y, color='blue', label='GD with Momentum')\n",
        "\n",
        "ax1.set_xlabel(r'$x$', fontsize=18)\n",
        "ax1.set_ylabel(r'$y$', fontsize=18)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support.' +\n",
              "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>')\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option)\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width, fig.canvas.height);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>')\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        event.shiftKey = false;\n",
              "        // Send a \"J\" for go to next cell\n",
              "        event.which = 74;\n",
              "        event.keyCode = 74;\n",
              "        manager.command_mode();\n",
              "        manager.handle_keydown(event);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='81b360c6-ac0d-42bd-951c-c3861abed3db'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "USwJS8roZDlQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Try out different combinations for the momentum scaler `alpha` and the learning rate `lr`. What are the impacts of these parameters? Does Momentum bring any benefit in this special example compared to GD without Momentum? - Briefly explain! (**1 point**)."
      ]
    },
    {
      "metadata": {
        "id": "8rVHDAT1Xe3r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ans :  Attached are the files with different combinations for alpha and learning rate. It is evident from the figures that higher value of alpha takes longer path to converge but they take less number of steps (We conclude this by comparing the time stamps of running the same optimisation job with a fixed LR). Also, we conclude that higher LR takes less time/less steps to converge. GD with Momentum takes a longer path but less time to converge, since it is based on averaging over a set of samples. \n",
        "\n",
        "alpha = 0.5 ; lr =0.5 : https://drive.google.com/file/d/1a-FUSh3VW8ZHby7rJfo6O3vOPZA1cxmo/view?usp=sharing\n",
        "alpha = 0.5 ; lr =0.2  : https://drive.google.com/file/d/1Gx1iNy077_TL2YnzfL2k53rkzmHmkf-0/view?usp=sharing\n",
        "alpha = 0.2 ; lr =0.9 : https://drive.google.com/file/d/17UGhbdvXMzIlUoTJ7aEUpQjUTdJBzZeO/view?usp=sharing\n",
        "alpha = 0.9 ; lr =0.2 : https://drive.google.com/file/d/1_Hoa-nXu2X1q0gP8itnGgGqiz-Y40-Mj/view?usp=sharing\n",
        "alpha = 0.2 ; lr =0.2 : https://drive.google.com/file/d/1VnaCIcWAUDUGVsbkRNn5z4pxkaEP0TDf/view?usp=sharing\n",
        "alpha = 0.9 ; lr =0.9 : https://drive.google.com/file/d/1769gC4V0s_93eEJ77tekWJtRBGaYF-qd/view?usp=sharing\n",
        "alpha = 0.0 ; lr =0.2 : (Simple GD) https://drive.google.com/file/d/1G7Hl8oqipDZv5ANXFME3EU0pRH8kRPGJ/view?usp=sharing"
      ]
    },
    {
      "metadata": {
        "id": "uFlt8I_pV_k3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U68Hb6n_ZDlT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $3$\n",
        "**Comments:** None\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "Hs_uQulKZDlX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1.3 Using Tensorflow's Optimizer Implementations"
      ]
    },
    {
      "metadata": {
        "id": "M8QxAu1JZDld",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Tensorflow does of course provide optimizers which you do not have to implement explictly. In order to compare these different optimizers, complete the code below. Use the following implementations from the tensorflow library:\n",
        "\n",
        "- [Gradient Descent](https://www.tensorflow.org/api_docs/python/tf/train/GradientDescentOptimizer)\n",
        "- [Gradient Descent with Momentum](https://www.tensorflow.org/api_docs/python/tf/train/MomentumOptimizer)\n",
        "- [RMSProp](https://www.tensorflow.org/api_docs/python/tf/train/RMSPropOptimizer) \n",
        "- [AdaGrad](https://www.tensorflow.org/api_docs/python/tf/train/AdagradOptimizer)\n",
        "\n",
        "(**0.5 points**)\n"
      ]
    },
    {
      "metadata": {
        "id": "plbh5oZOZDlh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# starting position\n",
        "start_x, start_y = 0.55, 0.6\n",
        "n_steps = 60\n",
        "\n",
        "# Write code to define GD, Momentum, RMSProp and Adagrad implementations on tf_z global variable defined by problem_3d\n",
        "\n",
        "with tf.variable_scope('gd', reuse=tf.AUTO_REUSE):\n",
        "    # TODO: Define Gradient Descent Optimizer with learning rate = 0.1\n",
        "    op_tf_optimize_z = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
        "    tf_optimize_z=op_tf_optimize_z.minimize(tf_z)\n",
        "\n",
        "with tf.variable_scope('momentum', reuse=tf.AUTO_REUSE):\n",
        "    # TODO: Define Gradient Descent with Nestrov's Momentum Optimizer with learning rate = 0.1 and momentum = 0.9\n",
        "    op_tf_mom_optimize_z = tf.train.MomentumOptimizer(learning_rate=0.1,momentum=0.9,use_nesterov=True)\n",
        "    tf_mom_optimize_z = op_tf_mom_optimize_z.minimize(tf_z)\n",
        "    \n",
        "with tf.variable_scope('rmsprop', reuse=tf.AUTO_REUSE):\n",
        "    # TODO: Define RMSProp with learning rate = 0.1\n",
        "    op_tf_rms_optimize_z = tf.train.RMSPropOptimizer(learning_rate=0.1)\n",
        "    tf_rms_optimize_z=op_tf_rms_optimize_z.minimize(tf_z)\n",
        "    \n",
        "with tf.variable_scope('adagrad', reuse=tf.AUTO_REUSE):\n",
        "    # TODO: Define Adagrad Optimizer with learning rate = 0.1\n",
        "    op_tf_ada_optimize_z = tf.train.AdagradOptimizer(learning_rate=0.1)\n",
        "    tf_ada_optimize_z=op_tf_ada_optimize_z.minimize(tf_z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_GfAHhT2ZDlp",
        "colab_type": "code",
        "outputId": "178753b5-b45f-4e5a-9b3a-cf3f388a440b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "cell_type": "code",
      "source": [
        "session.run(tf.global_variables_initializer())\n",
        "\n",
        "# Run vanilla GD on Error Surface\n",
        "session.run([tf_reinit_x, tf_reinit_y])\n",
        "\n",
        "opt_gd_points_x, opt_gd_points_y, opt_gd_points_z = [],[],[]\n",
        "opt_gd_points_x.append(start_x)\n",
        "opt_gd_points_y.append(start_y)\n",
        "opt_gd_points_z.append(func_z(start_x,start_y))\n",
        "\n",
        "print('Vanilla GD Optimization started')\n",
        "for step in range(n_steps):\n",
        "    session.run(tf_optimize_z)\n",
        "    x, y, z = session.run([tf_x, tf_y, tf_z])    \n",
        "    opt_gd_points_x.append(x)\n",
        "    opt_gd_points_y.append(y)\n",
        "    opt_gd_points_z.append(z)\n",
        "print('Vanilla GD Optimization finished')\n",
        "\n",
        "\n",
        "# Run Nestrov's Momentum GD on Error Surface\n",
        "session.run([tf_reinit_x, tf_reinit_y])\n",
        "\n",
        "opt_mom_points_x, opt_mom_points_y, opt_mom_points_z = [],[],[]\n",
        "opt_mom_points_x.append(start_x)\n",
        "opt_mom_points_y.append(start_y)\n",
        "opt_mom_points_z.append(func_z(start_x,start_y))\n",
        "\n",
        "\n",
        "\n",
        "print(\"Momentum Optimization started\")\n",
        "for step in range(n_steps):\n",
        "    session.run(tf_mom_optimize_z)\n",
        "    x, y, z = session.run([tf_x, tf_y, tf_z])    \n",
        "    opt_mom_points_x.append(x)\n",
        "    opt_mom_points_y.append(y)\n",
        "    opt_mom_points_z.append(z)\n",
        "print('Momentum Optimization finished')\n",
        "print(opt_mom_points_z)\n",
        "    \n",
        "# RMSProp\n",
        "session.run([tf_reinit_x, tf_reinit_y])\n",
        "\n",
        "opt_rms_points_x, opt_rms_points_y, opt_rms_points_z = [],[],[]\n",
        "opt_rms_points_x.append(start_x)\n",
        "opt_rms_points_y.append(start_y)\n",
        "opt_rms_points_z.append(func_z(start_x,start_y))\n",
        "\n",
        "print('RMSProp Optimization started')\n",
        "for step in range(n_steps):\n",
        "    session.run(tf_rms_optimize_z)\n",
        "    x, y, z = session.run([tf_x, tf_y, tf_z])    \n",
        "    opt_rms_points_x.append(x)\n",
        "    opt_rms_points_y.append(y)\n",
        "    opt_rms_points_z.append(z)\n",
        "print('RMSProp Optimization finished')\n",
        "\n",
        "\n",
        "# Run AdaGrad on Error Surface\n",
        "session.run([tf_reinit_x, tf_reinit_y])\n",
        "\n",
        "opt_ada_points_x, opt_ada_points_y, opt_ada_points_z = [],[],[]\n",
        "opt_ada_points_x.append(start_x)\n",
        "opt_ada_points_y.append(start_y)\n",
        "opt_ada_points_z.append(func_z(start_x,start_y))\n",
        "\n",
        "\n",
        "print('Adagrad Optimization started')\n",
        "for step in range(n_steps):\n",
        "    session.run(tf_ada_optimize_z)\n",
        "    x, y, z = session.run([tf_x, tf_y, tf_z])    \n",
        "    opt_ada_points_x.append(x)\n",
        "    opt_ada_points_y.append(y)\n",
        "    opt_ada_points_z.append(z)\n",
        "print('Adagrad Optimization finished')\n",
        "\n",
        "    \n",
        "range_x,range_y = np.arange(-1.0,2.0,0.2), np.arange(-2.0,2.0,0.2)\n",
        "X_lowres, Y_lowres = np.meshgrid(range_x, range_y)\n",
        "Z_lowres = func_z(X_lowres,Y_lowres)\n",
        "\n",
        "range_x,range_y = np.arange(-1.0,2.0,0.1), np.arange(-2.0,2.0,0.1)\n",
        "X_hires, Y_hires = np.meshgrid(range_x, range_y)\n",
        "Z_hires = func_z(X_hires,Y_hires)\n",
        "\n",
        "# Subplots visualizing the minimization steps\n",
        "\n",
        "fig = plt.figure(figsize=(9,4))\n",
        "\n",
        "epsilon = 0.0\n",
        "ax1 = fig.add_subplot(121,projection='3d')\n",
        "ax2 = fig.add_subplot(122)\n",
        "\n",
        "# plot\n",
        "ax1.plot_wireframe(X_lowres, Y_lowres, Z_lowres, linewidth=1, cmap=cm.jet, zorder=1, alpha=0.6)\n",
        "ax2.contour(X_hires, Y_hires, Z_hires, 32,  cmap=cm.jet)\n",
        "ax2.autoscale(False)\n",
        "\n",
        "# vanilla GD\n",
        "for idx, (x,y,z) in enumerate(zip(opt_gd_points_x, opt_gd_points_y, opt_gd_points_z)):\n",
        "    if idx != len(opt_gd_points_x)-1:\n",
        "        ax1.scatter(x,y,z + epsilon , color='blue', alpha=(idx+10)/(n_steps+10.0), zorder=100)\n",
        "        ax2.scatter(np.asarray(x),np.asarray(y) , color='blue')\n",
        "    else:\n",
        "        ax1.scatter(x,y,z + epsilon , color='blue', alpha=(idx+10)/(n_steps+10.0), label='GD', zorder=100)\n",
        "        ax2.scatter(x,y, color='blue', label='GD')\n",
        "\n",
        "# GD with momentum\n",
        "for idx, (x,y,z) in enumerate(zip(opt_mom_points_x, opt_mom_points_y, opt_mom_points_z)):\n",
        "    if idx != len(opt_mom_points_x)-1:\n",
        "        ax1.scatter(x,y , z + epsilon , color='yellow', alpha=(idx+10)/(n_steps+10.0), zorder=100)\n",
        "        ax2.scatter(x,y , color='yellow', alpha=(idx+10)/(n_steps+10.0))\n",
        "    else:\n",
        "        ax1.scatter(x,y,z + epsilon , color='yellow', alpha=(idx+10)/(n_steps+10.0), label='Momentum', zorder=100)\n",
        "        ax2.scatter(x,y, color='yellow', alpha=(idx+10)/(n_steps+10.0), label='Momentum')\n",
        "\n",
        "# RMSProp\n",
        "for idx, (x,y,z) in enumerate(zip(opt_rms_points_x, opt_rms_points_y, opt_rms_points_z)):\n",
        "    if idx != len(opt_rms_points_x)-1:\n",
        "        ax1.scatter(x,y,z + epsilon , color='purple', alpha=(idx+10)/(n_steps+10.0), zorder=100)\n",
        "        ax2.scatter(x,y , color='purple', alpha=(idx+10)/(n_steps+10.0))\n",
        "    else:\n",
        "        ax1.scatter(x,y,z + epsilon , color='purple', alpha=(idx+10)/(n_steps+10.0), label='RMSProp', zorder=100)\n",
        "        ax2.scatter(x,y, color='purple', alpha=(idx+10)/(n_steps+10.0), label='RMSProp')\n",
        "        \n",
        "# AdaGrad\n",
        "for idx, (x,y,z) in enumerate(zip(opt_ada_points_x, opt_ada_points_y, opt_ada_points_z)):\n",
        "    if idx != len(opt_ada_points_x)-1:\n",
        "        ax1.scatter(x,y,z + epsilon , color='green', alpha=(idx+10)/(n_steps+10.0), zorder=100)\n",
        "        ax2.scatter(x,y , color='green', alpha=(idx+10)/(n_steps+10.0), zorder=100)\n",
        "    else:\n",
        "        ax1.scatter(x,y,z + epsilon , color='green', alpha=(idx+10)/(n_steps+10.0), label='AdaGrad', zorder=100)\n",
        "        ax2.scatter(x,y,color='green', alpha=(idx+10)/(n_steps+10.0), label='AdaGrad', zorder=100)\n",
        "\n",
        "ax1.set_xlabel(r'$x$', fontsize=18)\n",
        "ax1.set_ylabel(r'$y$', fontsize=18)\n",
        "ax1.set_title(\"Error surface 3D\", fontsize=18)\n",
        "ax2.set_title('GD vs Nesterov Momentum vs RMSProp vs AdaGrad ', fontsize=12)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vanilla GD Optimization started\n",
            "Vanilla GD Optimization finished\n",
            "Momentum Optimization started\n",
            "Momentum Optimization finished\n",
            "[0.3279163883810402, 0.32745057, 0.3263924, 0.32391322, 0.31787026, 0.30317938, 0.27050322, 0.21357372, 0.15144593, 0.115852214, 0.10629766, 0.107473284, 0.110381395, 0.11160818, 0.1102093, 0.10622542, 0.10009432, 0.09240939, 0.08380949, 0.07492136, 0.066322654, 0.05850863, 0.051853746, 0.046571713, 0.042691577, 0.0400717, 0.038457207, 0.03755916, 0.037121937, 0.036957435, 0.036946997, 0.037025142, 0.037158832, 0.03733082, 0.037529267, 0.037742853, 0.03795947, 0.03816678, 0.03835345, 0.038510233, 0.03863076, 0.038711745, 0.03875286, 0.03875629, 0.038726047, 0.038667366, 0.038585976, 0.038487524, 0.038377196, 0.038259394, 0.038137652, 0.03801464, 0.037892256, 0.03777183, 0.037654266, 0.0375403, 0.037430584, 0.037325792, 0.037226662, 0.03713399, 0.037048556]\n",
            "RMSProp Optimization started\n",
            "RMSProp Optimization finished\n",
            "Adagrad Optimization started\n",
            "Adagrad Optimization finished\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "/* Put everything inside the global mpl namespace */\n",
              "window.mpl = {};\n",
              "\n",
              "\n",
              "mpl.get_websocket_type = function() {\n",
              "    if (typeof(WebSocket) !== 'undefined') {\n",
              "        return WebSocket;\n",
              "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
              "        return MozWebSocket;\n",
              "    } else {\n",
              "        alert('Your browser does not have WebSocket support.' +\n",
              "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
              "              'Firefox 4 and 5 are also supported but you ' +\n",
              "              'have to enable WebSockets in about:config.');\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
              "    this.id = figure_id;\n",
              "\n",
              "    this.ws = websocket;\n",
              "\n",
              "    this.supports_binary = (this.ws.binaryType != undefined);\n",
              "\n",
              "    if (!this.supports_binary) {\n",
              "        var warnings = document.getElementById(\"mpl-warnings\");\n",
              "        if (warnings) {\n",
              "            warnings.style.display = 'block';\n",
              "            warnings.textContent = (\n",
              "                \"This browser does not support binary websocket messages. \" +\n",
              "                    \"Performance may be slow.\");\n",
              "        }\n",
              "    }\n",
              "\n",
              "    this.imageObj = new Image();\n",
              "\n",
              "    this.context = undefined;\n",
              "    this.message = undefined;\n",
              "    this.canvas = undefined;\n",
              "    this.rubberband_canvas = undefined;\n",
              "    this.rubberband_context = undefined;\n",
              "    this.format_dropdown = undefined;\n",
              "\n",
              "    this.image_mode = 'full';\n",
              "\n",
              "    this.root = $('<div/>');\n",
              "    this._root_extra_style(this.root)\n",
              "    this.root.attr('style', 'display: inline-block');\n",
              "\n",
              "    $(parent_element).append(this.root);\n",
              "\n",
              "    this._init_header(this);\n",
              "    this._init_canvas(this);\n",
              "    this._init_toolbar(this);\n",
              "\n",
              "    var fig = this;\n",
              "\n",
              "    this.waiting = false;\n",
              "\n",
              "    this.ws.onopen =  function () {\n",
              "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
              "            fig.send_message(\"send_image_mode\", {});\n",
              "            if (mpl.ratio != 1) {\n",
              "                fig.send_message(\"set_dpi_ratio\", {'dpi_ratio': mpl.ratio});\n",
              "            }\n",
              "            fig.send_message(\"refresh\", {});\n",
              "        }\n",
              "\n",
              "    this.imageObj.onload = function() {\n",
              "            if (fig.image_mode == 'full') {\n",
              "                // Full images could contain transparency (where diff images\n",
              "                // almost always do), so we need to clear the canvas so that\n",
              "                // there is no ghosting.\n",
              "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
              "            }\n",
              "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
              "        };\n",
              "\n",
              "    this.imageObj.onunload = function() {\n",
              "        fig.ws.close();\n",
              "    }\n",
              "\n",
              "    this.ws.onmessage = this._make_on_message_function(this);\n",
              "\n",
              "    this.ondownload = ondownload;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_header = function() {\n",
              "    var titlebar = $(\n",
              "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
              "        'ui-helper-clearfix\"/>');\n",
              "    var titletext = $(\n",
              "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
              "        'text-align: center; padding: 3px;\"/>');\n",
              "    titlebar.append(titletext)\n",
              "    this.root.append(titlebar);\n",
              "    this.header = titletext[0];\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_canvas = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var canvas_div = $('<div/>');\n",
              "\n",
              "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
              "\n",
              "    function canvas_keyboard_event(event) {\n",
              "        return fig.key_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
              "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
              "    this.canvas_div = canvas_div\n",
              "    this._canvas_extra_style(canvas_div)\n",
              "    this.root.append(canvas_div);\n",
              "\n",
              "    var canvas = $('<canvas/>');\n",
              "    canvas.addClass('mpl-canvas');\n",
              "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
              "\n",
              "    this.canvas = canvas[0];\n",
              "    this.context = canvas[0].getContext(\"2d\");\n",
              "\n",
              "    var backingStore = this.context.backingStorePixelRatio ||\n",
              "\tthis.context.webkitBackingStorePixelRatio ||\n",
              "\tthis.context.mozBackingStorePixelRatio ||\n",
              "\tthis.context.msBackingStorePixelRatio ||\n",
              "\tthis.context.oBackingStorePixelRatio ||\n",
              "\tthis.context.backingStorePixelRatio || 1;\n",
              "\n",
              "    mpl.ratio = (window.devicePixelRatio || 1) / backingStore;\n",
              "\n",
              "    var rubberband = $('<canvas/>');\n",
              "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
              "\n",
              "    var pass_mouse_events = true;\n",
              "\n",
              "    canvas_div.resizable({\n",
              "        start: function(event, ui) {\n",
              "            pass_mouse_events = false;\n",
              "        },\n",
              "        resize: function(event, ui) {\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "        stop: function(event, ui) {\n",
              "            pass_mouse_events = true;\n",
              "            fig.request_resize(ui.size.width, ui.size.height);\n",
              "        },\n",
              "    });\n",
              "\n",
              "    function mouse_event_fn(event) {\n",
              "        if (pass_mouse_events)\n",
              "            return fig.mouse_event(event, event['data']);\n",
              "    }\n",
              "\n",
              "    rubberband.mousedown('button_press', mouse_event_fn);\n",
              "    rubberband.mouseup('button_release', mouse_event_fn);\n",
              "    // Throttle sequential mouse events to 1 every 20ms.\n",
              "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
              "\n",
              "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
              "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
              "\n",
              "    canvas_div.on(\"wheel\", function (event) {\n",
              "        event = event.originalEvent;\n",
              "        event['data'] = 'scroll'\n",
              "        if (event.deltaY < 0) {\n",
              "            event.step = 1;\n",
              "        } else {\n",
              "            event.step = -1;\n",
              "        }\n",
              "        mouse_event_fn(event);\n",
              "    });\n",
              "\n",
              "    canvas_div.append(canvas);\n",
              "    canvas_div.append(rubberband);\n",
              "\n",
              "    this.rubberband = rubberband;\n",
              "    this.rubberband_canvas = rubberband[0];\n",
              "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
              "    this.rubberband_context.strokeStyle = \"#000000\";\n",
              "\n",
              "    this._resize_canvas = function(width, height) {\n",
              "        // Keep the size of the canvas, canvas container, and rubber band\n",
              "        // canvas in synch.\n",
              "        canvas_div.css('width', width)\n",
              "        canvas_div.css('height', height)\n",
              "\n",
              "        canvas.attr('width', width * mpl.ratio);\n",
              "        canvas.attr('height', height * mpl.ratio);\n",
              "        canvas.attr('style', 'width: ' + width + 'px; height: ' + height + 'px;');\n",
              "\n",
              "        rubberband.attr('width', width);\n",
              "        rubberband.attr('height', height);\n",
              "    }\n",
              "\n",
              "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
              "    // upon first draw.\n",
              "    this._resize_canvas(600, 600);\n",
              "\n",
              "    // Disable right mouse context menu.\n",
              "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
              "        return false;\n",
              "    });\n",
              "\n",
              "    function set_focus () {\n",
              "        canvas.focus();\n",
              "        canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    window.setTimeout(set_focus, 100);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>')\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items) {\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) {\n",
              "            // put a spacer in here.\n",
              "            continue;\n",
              "        }\n",
              "        var button = $('<button/>');\n",
              "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
              "                        'ui-button-icon-only');\n",
              "        button.attr('role', 'button');\n",
              "        button.attr('aria-disabled', 'false');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "\n",
              "        var icon_img = $('<span/>');\n",
              "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
              "        icon_img.addClass(image);\n",
              "        icon_img.addClass('ui-corner-all');\n",
              "\n",
              "        var tooltip_span = $('<span/>');\n",
              "        tooltip_span.addClass('ui-button-text');\n",
              "        tooltip_span.html(tooltip);\n",
              "\n",
              "        button.append(icon_img);\n",
              "        button.append(tooltip_span);\n",
              "\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    var fmt_picker_span = $('<span/>');\n",
              "\n",
              "    var fmt_picker = $('<select/>');\n",
              "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
              "    fmt_picker_span.append(fmt_picker);\n",
              "    nav_element.append(fmt_picker_span);\n",
              "    this.format_dropdown = fmt_picker[0];\n",
              "\n",
              "    for (var ind in mpl.extensions) {\n",
              "        var fmt = mpl.extensions[ind];\n",
              "        var option = $(\n",
              "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
              "        fmt_picker.append(option)\n",
              "    }\n",
              "\n",
              "    // Add hover states to the ui-buttons\n",
              "    $( \".ui-button\" ).hover(\n",
              "        function() { $(this).addClass(\"ui-state-hover\");},\n",
              "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
              "    );\n",
              "\n",
              "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
              "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
              "    // which will in turn request a refresh of the image.\n",
              "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_message = function(type, properties) {\n",
              "    properties['type'] = type;\n",
              "    properties['figure_id'] = this.id;\n",
              "    this.ws.send(JSON.stringify(properties));\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.send_draw_message = function() {\n",
              "    if (!this.waiting) {\n",
              "        this.waiting = true;\n",
              "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    var format_dropdown = fig.format_dropdown;\n",
              "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
              "    fig.ondownload(fig, format);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
              "    var size = msg['size'];\n",
              "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
              "        fig._resize_canvas(size[0], size[1]);\n",
              "        fig.send_message(\"refresh\", {});\n",
              "    };\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
              "    var x0 = msg['x0'] / mpl.ratio;\n",
              "    var y0 = (fig.canvas.height - msg['y0']) / mpl.ratio;\n",
              "    var x1 = msg['x1'] / mpl.ratio;\n",
              "    var y1 = (fig.canvas.height - msg['y1']) / mpl.ratio;\n",
              "    x0 = Math.floor(x0) + 0.5;\n",
              "    y0 = Math.floor(y0) + 0.5;\n",
              "    x1 = Math.floor(x1) + 0.5;\n",
              "    y1 = Math.floor(y1) + 0.5;\n",
              "    var min_x = Math.min(x0, x1);\n",
              "    var min_y = Math.min(y0, y1);\n",
              "    var width = Math.abs(x1 - x0);\n",
              "    var height = Math.abs(y1 - y0);\n",
              "\n",
              "    fig.rubberband_context.clearRect(\n",
              "        0, 0, fig.canvas.width, fig.canvas.height);\n",
              "\n",
              "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
              "    // Updates the figure title.\n",
              "    fig.header.textContent = msg['label'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
              "    var cursor = msg['cursor'];\n",
              "    switch(cursor)\n",
              "    {\n",
              "    case 0:\n",
              "        cursor = 'pointer';\n",
              "        break;\n",
              "    case 1:\n",
              "        cursor = 'default';\n",
              "        break;\n",
              "    case 2:\n",
              "        cursor = 'crosshair';\n",
              "        break;\n",
              "    case 3:\n",
              "        cursor = 'move';\n",
              "        break;\n",
              "    }\n",
              "    fig.rubberband_canvas.style.cursor = cursor;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
              "    fig.message.textContent = msg['message'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
              "    // Request the server to send over a new figure.\n",
              "    fig.send_draw_message();\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
              "    fig.image_mode = msg['mode'];\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Called whenever the canvas gets updated.\n",
              "    this.send_message(\"ack\", {});\n",
              "}\n",
              "\n",
              "// A function to construct a web socket function for onmessage handling.\n",
              "// Called in the figure constructor.\n",
              "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
              "    return function socket_on_message(evt) {\n",
              "        if (evt.data instanceof Blob) {\n",
              "            /* FIXME: We get \"Resource interpreted as Image but\n",
              "             * transferred with MIME type text/plain:\" errors on\n",
              "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
              "             * to be part of the websocket stream */\n",
              "            evt.data.type = \"image/png\";\n",
              "\n",
              "            /* Free the memory for the previous frames */\n",
              "            if (fig.imageObj.src) {\n",
              "                (window.URL || window.webkitURL).revokeObjectURL(\n",
              "                    fig.imageObj.src);\n",
              "            }\n",
              "\n",
              "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
              "                evt.data);\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
              "            fig.imageObj.src = evt.data;\n",
              "            fig.updated_canvas_event();\n",
              "            fig.waiting = false;\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        var msg = JSON.parse(evt.data);\n",
              "        var msg_type = msg['type'];\n",
              "\n",
              "        // Call the  \"handle_{type}\" callback, which takes\n",
              "        // the figure and JSON message as its only arguments.\n",
              "        try {\n",
              "            var callback = fig[\"handle_\" + msg_type];\n",
              "        } catch (e) {\n",
              "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
              "            return;\n",
              "        }\n",
              "\n",
              "        if (callback) {\n",
              "            try {\n",
              "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
              "                callback(fig, msg);\n",
              "            } catch (e) {\n",
              "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
              "            }\n",
              "        }\n",
              "    };\n",
              "}\n",
              "\n",
              "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
              "mpl.findpos = function(e) {\n",
              "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
              "    var targ;\n",
              "    if (!e)\n",
              "        e = window.event;\n",
              "    if (e.target)\n",
              "        targ = e.target;\n",
              "    else if (e.srcElement)\n",
              "        targ = e.srcElement;\n",
              "    if (targ.nodeType == 3) // defeat Safari bug\n",
              "        targ = targ.parentNode;\n",
              "\n",
              "    // jQuery normalizes the pageX and pageY\n",
              "    // pageX,Y are the mouse positions relative to the document\n",
              "    // offset() returns the position of the element relative to the document\n",
              "    var x = e.pageX - $(targ).offset().left;\n",
              "    var y = e.pageY - $(targ).offset().top;\n",
              "\n",
              "    return {\"x\": x, \"y\": y};\n",
              "};\n",
              "\n",
              "/*\n",
              " * return a copy of an object with only non-object keys\n",
              " * we need this to avoid circular references\n",
              " * http://stackoverflow.com/a/24161582/3208463\n",
              " */\n",
              "function simpleKeys (original) {\n",
              "  return Object.keys(original).reduce(function (obj, key) {\n",
              "    if (typeof original[key] !== 'object')\n",
              "        obj[key] = original[key]\n",
              "    return obj;\n",
              "  }, {});\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.mouse_event = function(event, name) {\n",
              "    var canvas_pos = mpl.findpos(event)\n",
              "\n",
              "    if (name === 'button_press')\n",
              "    {\n",
              "        this.canvas.focus();\n",
              "        this.canvas_div.focus();\n",
              "    }\n",
              "\n",
              "    var x = canvas_pos.x * mpl.ratio;\n",
              "    var y = canvas_pos.y * mpl.ratio;\n",
              "\n",
              "    this.send_message(name, {x: x, y: y, button: event.button,\n",
              "                             step: event.step,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "\n",
              "    /* This prevents the web browser from automatically changing to\n",
              "     * the text insertion cursor when the button is pressed.  We want\n",
              "     * to control all of the cursor setting manually through the\n",
              "     * 'cursor' event from matplotlib */\n",
              "    event.preventDefault();\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    // Handle any extra behaviour associated with a key event\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.key_event = function(event, name) {\n",
              "\n",
              "    // Prevent repeat events\n",
              "    if (name == 'key_press')\n",
              "    {\n",
              "        if (event.which === this._key)\n",
              "            return;\n",
              "        else\n",
              "            this._key = event.which;\n",
              "    }\n",
              "    if (name == 'key_release')\n",
              "        this._key = null;\n",
              "\n",
              "    var value = '';\n",
              "    if (event.ctrlKey && event.which != 17)\n",
              "        value += \"ctrl+\";\n",
              "    if (event.altKey && event.which != 18)\n",
              "        value += \"alt+\";\n",
              "    if (event.shiftKey && event.which != 16)\n",
              "        value += \"shift+\";\n",
              "\n",
              "    value += 'k';\n",
              "    value += event.which.toString();\n",
              "\n",
              "    this._key_event_extra(event, name);\n",
              "\n",
              "    this.send_message(name, {key: value,\n",
              "                             guiEvent: simpleKeys(event)});\n",
              "    return false;\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
              "    if (name == 'download') {\n",
              "        this.handle_save(this, null);\n",
              "    } else {\n",
              "        this.send_message(\"toolbar_button\", {name: name});\n",
              "    }\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
              "    this.message.textContent = tooltip;\n",
              "};\n",
              "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
              "\n",
              "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
              "\n",
              "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
              "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
              "    // object with the appropriate methods. Currently this is a non binary\n",
              "    // socket, so there is still some room for performance tuning.\n",
              "    var ws = {};\n",
              "\n",
              "    ws.close = function() {\n",
              "        comm.close()\n",
              "    };\n",
              "    ws.send = function(m) {\n",
              "        //console.log('sending', m);\n",
              "        comm.send(m);\n",
              "    };\n",
              "    // Register the callback with on_msg.\n",
              "    comm.on_msg(function(msg) {\n",
              "        //console.log('receiving', msg['content']['data'], msg);\n",
              "        // Pass the mpl event to the overridden (by mpl) onmessage function.\n",
              "        ws.onmessage(msg['content']['data'])\n",
              "    });\n",
              "    return ws;\n",
              "}\n",
              "\n",
              "mpl.mpl_figure_comm = function(comm, msg) {\n",
              "    // This is the function which gets called when the mpl process\n",
              "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
              "\n",
              "    var id = msg.content.data.id;\n",
              "    // Get hold of the div created by the display call when the Comm\n",
              "    // socket was opened in Python.\n",
              "    var element = $(\"#\" + id);\n",
              "    var ws_proxy = comm_websocket_adapter(comm)\n",
              "\n",
              "    function ondownload(figure, format) {\n",
              "        window.open(figure.imageObj.src);\n",
              "    }\n",
              "\n",
              "    var fig = new mpl.figure(id, ws_proxy,\n",
              "                           ondownload,\n",
              "                           element.get(0));\n",
              "\n",
              "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
              "    // web socket which is closed, not our websocket->open comm proxy.\n",
              "    ws_proxy.onopen();\n",
              "\n",
              "    fig.parent_element = element.get(0);\n",
              "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
              "    if (!fig.cell_info) {\n",
              "        console.error(\"Failed to find cell for figure\", id, fig);\n",
              "        return;\n",
              "    }\n",
              "\n",
              "    var output_index = fig.cell_info[2]\n",
              "    var cell = fig.cell_info[0];\n",
              "\n",
              "};\n",
              "\n",
              "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
              "    var width = fig.canvas.width/mpl.ratio\n",
              "    fig.root.unbind('remove')\n",
              "\n",
              "    // Update the output cell to use the data from the current canvas.\n",
              "    fig.push_to_output();\n",
              "    var dataURL = fig.canvas.toDataURL();\n",
              "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
              "    // the notebook keyboard shortcuts fail.\n",
              "    IPython.keyboard_manager.enable()\n",
              "    $(fig.parent_element).html('<img src=\"' + dataURL + '\" width=\"' + width + '\">');\n",
              "    fig.close_ws(fig, msg);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.close_ws = function(fig, msg){\n",
              "    fig.send_message('closing', msg);\n",
              "    // fig.ws.close()\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
              "    // Turn the data on the canvas into data in the output cell.\n",
              "    var width = this.canvas.width/mpl.ratio\n",
              "    var dataURL = this.canvas.toDataURL();\n",
              "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\" width=\"' + width + '\">';\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.updated_canvas_event = function() {\n",
              "    // Tell IPython that the notebook contents must change.\n",
              "    IPython.notebook.set_dirty(true);\n",
              "    this.send_message(\"ack\", {});\n",
              "    var fig = this;\n",
              "    // Wait a second, then push the new image to the DOM so\n",
              "    // that it is saved nicely (might be nice to debounce this).\n",
              "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._init_toolbar = function() {\n",
              "    var fig = this;\n",
              "\n",
              "    var nav_element = $('<div/>')\n",
              "    nav_element.attr('style', 'width: 100%');\n",
              "    this.root.append(nav_element);\n",
              "\n",
              "    // Define a callback function for later on.\n",
              "    function toolbar_event(event) {\n",
              "        return fig.toolbar_button_onclick(event['data']);\n",
              "    }\n",
              "    function toolbar_mouse_event(event) {\n",
              "        return fig.toolbar_button_onmouseover(event['data']);\n",
              "    }\n",
              "\n",
              "    for(var toolbar_ind in mpl.toolbar_items){\n",
              "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
              "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
              "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
              "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
              "\n",
              "        if (!name) { continue; };\n",
              "\n",
              "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
              "        button.click(method_name, toolbar_event);\n",
              "        button.mouseover(tooltip, toolbar_mouse_event);\n",
              "        nav_element.append(button);\n",
              "    }\n",
              "\n",
              "    // Add the status bar.\n",
              "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
              "    nav_element.append(status_bar);\n",
              "    this.message = status_bar[0];\n",
              "\n",
              "    // Add the close button to the window.\n",
              "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
              "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
              "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
              "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
              "    buttongrp.append(button);\n",
              "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
              "    titlebar.prepend(buttongrp);\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._root_extra_style = function(el){\n",
              "    var fig = this\n",
              "    el.on(\"remove\", function(){\n",
              "\tfig.close_ws(fig, {});\n",
              "    });\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._canvas_extra_style = function(el){\n",
              "    // this is important to make the div 'focusable\n",
              "    el.attr('tabindex', 0)\n",
              "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
              "    // off when our div gets focus\n",
              "\n",
              "    // location in version 3\n",
              "    if (IPython.notebook.keyboard_manager) {\n",
              "        IPython.notebook.keyboard_manager.register_events(el);\n",
              "    }\n",
              "    else {\n",
              "        // location in version 2\n",
              "        IPython.keyboard_manager.register_events(el);\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
              "    var manager = IPython.notebook.keyboard_manager;\n",
              "    if (!manager)\n",
              "        manager = IPython.keyboard_manager;\n",
              "\n",
              "    // Check for shift+enter\n",
              "    if (event.shiftKey && event.which == 13) {\n",
              "        this.canvas_div.blur();\n",
              "        event.shiftKey = false;\n",
              "        // Send a \"J\" for go to next cell\n",
              "        event.which = 74;\n",
              "        event.keyCode = 74;\n",
              "        manager.command_mode();\n",
              "        manager.handle_keydown(event);\n",
              "    }\n",
              "}\n",
              "\n",
              "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
              "    fig.ondownload(fig, null);\n",
              "}\n",
              "\n",
              "\n",
              "mpl.find_output_cell = function(html_output) {\n",
              "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
              "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
              "    // IPython event is triggered only after the cells have been serialised, which for\n",
              "    // our purposes (turning an active figure into a static one), is too late.\n",
              "    var cells = IPython.notebook.get_cells();\n",
              "    var ncells = cells.length;\n",
              "    for (var i=0; i<ncells; i++) {\n",
              "        var cell = cells[i];\n",
              "        if (cell.cell_type === 'code'){\n",
              "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
              "                var data = cell.output_area.outputs[j];\n",
              "                if (data.data) {\n",
              "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
              "                    data = data.data;\n",
              "                }\n",
              "                if (data['text/html'] == html_output) {\n",
              "                    return [cell, data, j];\n",
              "                }\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "}\n",
              "\n",
              "// Register the function which deals with the matplotlib target/channel.\n",
              "// The kernel may be null if the page has been refreshed.\n",
              "if (IPython.notebook.kernel != null) {\n",
              "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
              "}\n"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div id='1e8fa64d-f5cb-4067-bc0c-cff3017a3123'></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "tvqkWhj8mm9h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Figure : https://drive.google.com/file/d/17ivbaK0rxVcxCwIQzrk8VKl5mnjD47n_/view?usp=sharing"
      ]
    },
    {
      "metadata": {
        "id": "fP8im9qKZDlv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Evaluate the function `z` at the termination points for each algorithm from the plots above. Which algorithm has made better progress in minimizing `z`?. Is it generally good to  always use this method? Briefly explain your findings. (**1.5 points**)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IRubIjrVXwF7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ans : Adagrad Optimizer has the best progress in minimizing z. Yes, it is good to use this method because since it dynamically adapts the learning rate, the frequently occuring features get a lower learning rate and the rare features are being noticed by the model when encountered meaning the model can now identify the predictive but infrequent features more easily than if the learning rate was the same. "
      ]
    },
    {
      "metadata": {
        "id": "uxZ2pr5BZDl0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $2$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "RjJiLJDkZDl8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2. RNN Implementation in Tensorflow$~$ (14 points)\n",
        "\n",
        "In the following exercise you should implement a simple Recurrent Neural Network using tensorflow. The task we consider here is learning a certain repeating pattern of digits.\n",
        "\n",
        "Consider the following infinite sequence: \n",
        "\n",
        "$$1, 2, 2, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 5, ..., 9, 1, 2, 2, 3, ...$$\n",
        "\n",
        "A digit $i \\in [1, 9]$ appears i times subsequently followed by $i+1$. After $i$ equals to 9, the sequence continues with $i = 1$. \n",
        "\n",
        "While the recognition of this pattern is easy for humans, in this exercise, we want to train a recurrent neural network such that it is able to predict the next digit for a given sequence.\n",
        "\n",
        "### 2.1. Prepraring the data\n",
        "\n",
        "First, we have to generate our training and test data. The function `generate_dataset` should return a certain amount of valid sequence snippets from the pattern described above with a given sample_size.\n",
        "\n",
        "Valid sequcences of size 5 are for example:\n",
        "- $[1, 2, 2, 3, 3]$ - expected prediction: 3\n",
        "- $[9, 9, 1, 2, 2]$ - expected prediction: 3\n",
        "- $[7, 7, 7, 7, 7]$ - expected prediction: 7 or 8\n",
        "\n",
        "not valid sequcences of size 5 are for example:\n",
        "- $[1, 1, 2, 2, 3]$\n",
        "- $[3, 4, 4, 5, 5]$\n",
        "- $[9, 0, 1, 2, 2]$\n",
        "\n",
        "Complete the function implementations below. (**1.5 points**)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EC4iNzMcZDl_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_seq_samples(start=1, length=100):\n",
        "\n",
        "    res_sequence = []\n",
        "    \n",
        "    # TODO: Implement this function returning one sequence starting with the digit 'start' containing 'length' items\n",
        "    # modified to return length+1 items to make the generating prediction more efficient in the generate_dataset function\n",
        "    curr=start\n",
        "    count=np.random.randint(1,start+1)\n",
        "    while len(res_sequence)<length+1:\n",
        "      res_sequence=res_sequence+[curr]*count\n",
        "      if curr==9:\n",
        "          curr=1\n",
        "      else:\n",
        "         curr=curr+1\n",
        "      count=curr\n",
        "    \n",
        "    res_sequence=res_sequence[:length+1]\n",
        "    return res_sequence\n",
        "\n",
        "def generate_dataset(sample_count, sample_size):\n",
        "\n",
        "    dataset = []\n",
        "    labels = []\n",
        "\n",
        "    # TODO: Implement this function returning an array containing 'sample_count' generated samples of length 'sample_size'\n",
        "    # and an array containing the corresponing digits which should get predicted\n",
        "    i=0\n",
        "    while i<sample_count:\n",
        "      start=np.random.randint(1,10)\n",
        "      seq=get_seq_samples(start=start,length=sample_size)\n",
        "      dataset.append(seq[:-1])\n",
        "      labels.append(seq[-1])\n",
        "      i=i+1\n",
        "\n",
        "    return np.array(dataset), np.array(labels)   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gyKK5FKwZDmE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $1.5$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "zXBmak6PZ5jr",
        "colab_type": "code",
        "outputId": "def1d4ec-0455-4c66-fee8-bba7c30731c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "cell_type": "code",
      "source": [
        "generate_dataset(40,2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[9, 9],\n",
              "        [5, 5],\n",
              "        [7, 7],\n",
              "        [6, 6],\n",
              "        [6, 7],\n",
              "        [7, 7],\n",
              "        [8, 8],\n",
              "        [8, 8],\n",
              "        [2, 3],\n",
              "        [6, 6],\n",
              "        [8, 8],\n",
              "        [2, 3],\n",
              "        [9, 9],\n",
              "        [3, 4],\n",
              "        [8, 8],\n",
              "        [5, 5],\n",
              "        [6, 6],\n",
              "        [8, 8],\n",
              "        [7, 7],\n",
              "        [5, 5],\n",
              "        [7, 7],\n",
              "        [6, 6],\n",
              "        [2, 3],\n",
              "        [8, 9],\n",
              "        [2, 2],\n",
              "        [1, 2],\n",
              "        [6, 7],\n",
              "        [8, 8],\n",
              "        [2, 3],\n",
              "        [6, 6],\n",
              "        [3, 3],\n",
              "        [5, 5],\n",
              "        [5, 6],\n",
              "        [8, 8],\n",
              "        [4, 5],\n",
              "        [6, 6],\n",
              "        [8, 8],\n",
              "        [7, 7],\n",
              "        [8, 8],\n",
              "        [6, 7]]),\n",
              " array([1, 5, 7, 6, 7, 8, 8, 8, 3, 6, 8, 3, 9, 4, 8, 5, 6, 8, 7, 5, 7, 6,\n",
              "        3, 9, 3, 2, 7, 8, 3, 6, 3, 6, 6, 8, 5, 6, 8, 7, 8, 7]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "w6zqEAsDZDmF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.2. Model Setup\n",
        "\n",
        "In the next step we implement a recurrent many-to-one neural network which processes batches of input sequences to one single output value. \n",
        "\n",
        "An RNN-cell implements the following function:\n",
        "\n",
        "$$a^{(t)} = W\\cdot h^{(t-1)} + U\\cdot x^{(t)} + b$$ \n",
        "$$h^{(t)} = tanh(a^{(t)})$$\n",
        "$$...$$\n",
        "$$o = V\\cdot h^{(n)} + c$$\n",
        "\n",
        "$t$ indicates the time step iteration, $b$ and $c$ are bias values and $U, V $ and $W$ weight parameters. $o$ is the resulting output which gets computed after processing a sequence of $n$ numbers.\n",
        "\n",
        "a) To get familiar with the model design, draw an unfolded model graph for input sequences of length 3 (check the images in the [**Deep Learning Book - Chapter 10.2**](https://www.deeplearningbook.org/contents/rnn.html) ). For each cell, state its variable name. Also include where which mathematical operation ($+, \\cdot, tanh()$) should be applied. (**2 points**)\n",
        "\n",
        "\n",
        "b) Assume you have implemented the model from a) in tensorflow. For each cell in your image, add the tensor shapes (array dimensions) when the `batch_size` is set to 4 sequences. Assume that the inputs are sequences of digits, the outputs are one-hot encoded and the RNN layer size is 50. (**2 points**)\n",
        "\n",
        "\n",
        "c) Finally, your task is to complete the following code at the `# TODO` sections, so that the neural network is able to process batches of size `batch_size` of digit sequences of the length `input_seq_len`. The hidden RNN size is given by `n_hidden`. (**5 points**)"
      ]
    },
    {
      "metadata": {
        "id": "UWFJjbl7hRE-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ans : ![2.2 Unfolded Model Graph]https://drive.google.com/open?id=17koUMxbTzelP4OygxzByY-OFjmCDJKEr"
      ]
    },
    {
      "metadata": {
        "id": "OIifyj9XZDmH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.01\n",
        "epochs = 70\n",
        "batch_size = 5\n",
        "\n",
        "# length of a single sequence\n",
        "input_seq_len = 10\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 90\n",
        "\n",
        "n_vocab=9\n",
        "\n",
        "\n",
        "RNN_graph = tf.Graph()\n",
        "with RNN_graph.as_default():\n",
        "\n",
        "    # tf Graph input: X = sequences, Y = digits to predict \n",
        "    batchX_placeholder = tf.placeholder(tf.int32, [batch_size, input_seq_len])\n",
        "    batchY_placeholder = tf.placeholder(tf.int32, [batch_size, 1])\n",
        "\n",
        "    # init_state = h0\n",
        "    init_state = tf.Variable(tf.random_normal([batch_size, n_hidden]))\n",
        "\n",
        "    # TODO: RNN output node weights and biases - set the tf.Variables with correct shapes and random_normal initialization\n",
        "    weights = {\n",
        "        'U': tf.Variable(np.random.rand(n_vocab,n_hidden), dtype=tf.float32),\n",
        "        'W': tf.Variable(np.random.rand(n_hidden, n_hidden), dtype=tf.float32),\n",
        "        'V': tf.Variable(np.random.rand(n_hidden, n_vocab), dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    biases = {\n",
        "        'b': tf.Variable(np.zeros((1,n_hidden)), dtype=tf.float32),\n",
        "        'c': tf.Variable(np.zeros((1,n_vocab)), dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    # TODO: setup graph for the RNN\n",
        "    inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
        "    labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
        "    labels = tf.one_hot(labels_series,depth=n_vocab)\n",
        "    \n",
        "    h_prev = init_state\n",
        "    states = []\n",
        "    for t in range(input_seq_len):\n",
        "#       input_t = tf.reshape(input_series[t], [batch_size, 1])\n",
        "      x_t = tf.one_hot(inputs_series[t], depth=n_vocab)\n",
        "      a_t = tf.matmul(h_prev,weights['W']) + tf.matmul(x_t,weights['U']) +biases['b']\n",
        "      h_t = tf.tanh(a_t)\n",
        "      states.append(h_t)\n",
        "      h_prev = h_t\n",
        "    \n",
        "    # TODO: network output\n",
        "    \n",
        "    o = tf.matmul(h_t,weights['V'])+biases['c']\n",
        "    predictions = tf.nn.softmax(o)\n",
        "\n",
        "    # class predictions\n",
        "    predictions = tf.argmax(o, axis=1)\n",
        "    predictions = tf.reshape(predictions, [-1, 1])\n",
        "\n",
        "    # TODO: accuracy \n",
        "    correct_prediction = tf.equal(predictions,labels_series)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # TODO: loss of the current batch\n",
        "    total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels,logits=o))\n",
        "    train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(total_loss)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N4JgoV6lZDmW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $9$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "vQJhgurJZDmg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.3. Training and Testing\n",
        "\n",
        "a) For the training, generate a training set with 2000 and a test set of 100 samples. (**0.5 points**)\n",
        "\n",
        "b) Fill in the `#TODO` sections so that after each 100th batch iteration, the current batch sequences get printed with the prediction and ground truth digit in one line like this: \n",
        "\n",
        "`\n",
        "Epoch 34 Batch 200\n",
        "Sequence: 9 9 1 2 2 3 3 3 4 4 - prediction: 5 label: 4\n",
        "Sequence: 5 5 5 5 6 6 6 6 6 6 - prediction: 7 label: 7\n",
        "Sequence: 1 2 2 3 3 3 4 4 4 4 - prediction: 5 label: 5\n",
        "Sequence: 4 4 4 4 5 5 5 5 5 6 - prediction: 5 label: 6\n",
        "Sequence: 7 7 7 7 7 7 7 8 8 8 - prediction: 5 label: 8\n",
        "`\n",
        "\n",
        "(**1 point**)"
      ]
    },
    {
      "metadata": {
        "id": "V9qc6i7jZDmi",
        "colab_type": "code",
        "outputId": "b044f5ea-16de-413f-c339-e21d9e760664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5050
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "# TODO: Generate Train and Test datasets\n",
        "X_train, y_train = generate_dataset(sample_count=2000,sample_size=10)\n",
        "X_test, y_test = generate_dataset(sample_count=100,sample_size=10)\n",
        "\n",
        "num_batches = len(X_train) // batch_size\n",
        "\n",
        "# Launch the Session\n",
        "with tf.Session(graph=RNN_graph) as session:\n",
        "\n",
        "    # label shift for loss computation\n",
        "    y_train = y_train - 1\n",
        "    \n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    session.run(init)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "\n",
        "        print(\"\\nEpoch {}\".format(cur_epoch))\n",
        "        acc_sum = 0\n",
        "        loss_sum = 0\n",
        "\n",
        "        indices = np.random.permutation(len(X_train))\n",
        "\n",
        "        for cur_batch_count in range(num_batches):\n",
        "\n",
        "            batch_indices = np.array(indices[cur_batch_count:cur_batch_count + batch_size])\n",
        "\n",
        "            x_batch = X_train[batch_indices]\n",
        "            y_batch = y_train[batch_indices]    \n",
        "            \n",
        "            preds, cur_loss, cur_acc, _ = session.run([predictions, total_loss, accuracy, train_step], feed_dict={batchX_placeholder: x_batch, \n",
        "                                                                                    batchY_placeholder: np.reshape(y_batch, [batch_size, 1])\n",
        "                                                                                    })\n",
        "            acc_sum += cur_acc\n",
        "            loss_sum += cur_loss\n",
        "            \n",
        "            # TODO: Implement the printing of the current batch predictions for batch 0, 100, 200, etc.\n",
        "            if cur_batch_count%100 ==0:\n",
        "              print('Batch '+ str(cur_batch_count), end=\"\")\n",
        "              for i in range(batch_size):\n",
        "                s=(' Sequence: {} - prediction {} label: {} ').format(x_batch[i],preds[i],y_batch[i])\n",
        "              print(s,end=\"\")\n",
        "            \n",
        "            \n",
        "        print(\"\\nAvg Training Loss: {} Avg Train Accuracy: {}\".format(loss_sum / num_batches, acc_sum / num_batches))\n",
        "        \n",
        "    # Testing\n",
        "    num_batches = len(X_test) // batch_size\n",
        "    y_test = y_test - 1\n",
        "\n",
        "    acc_sum = 0\n",
        "    loss_sum = 0\n",
        "\n",
        "    for cur_batch_count in range(num_batches):\n",
        "        x_batch = X_test[cur_batch_count:cur_batch_count+batch_size]\n",
        "        y_batch = y_test[cur_batch_count:cur_batch_count+batch_size]            \n",
        "\n",
        "        cur_loss, cur_acc = session.run([total_loss, accuracy], feed_dict={batchX_placeholder: x_batch, \n",
        "                                                                           batchY_placeholder: np.reshape(y_batch, [batch_size, 1])\n",
        "                                                                           })\n",
        "\n",
        "        acc_sum += cur_acc\n",
        "        loss_sum += cur_loss\n",
        "\n",
        "    print(\"\\nFinal Test Loss: {} Final Test Accuracy: {}\".format(loss_sum / num_batches, acc_sum / num_batches))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [1] label: 4 Batch 100 Sequence: [7 7 7 8 8 8 8 8 8 8] - prediction [4] label: 7 Batch 200 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [4] label: 6 Batch 300 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [6] label: 4 \n",
            "Avg Training Loss: 2.3982154205441475 Avg Train Accuracy: 0.2640000005811453\n",
            "\n",
            "Epoch 1\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [7] label: 4 Batch 100 Sequence: [5 5 6 6 6 6 6 6 7 7] - prediction [4] label: 6 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 300 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.2896947883069516 Avg Train Accuracy: 0.3055000020377338\n",
            "\n",
            "Epoch 2\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [4] label: 4 Batch 100 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [8] label: 5 Batch 200 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [7] label: 5 Batch 300 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [4] label: 6 \n",
            "Avg Training Loss: 2.4210671579837797 Avg Train Accuracy: 0.2910000015795231\n",
            "\n",
            "Epoch 3\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [6] label: 4 Batch 100 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [4] label: 7 Batch 200 Sequence: [9 9 9 9 9 9 9 9 9 1] - prediction [2] label: 1 Batch 300 Sequence: [8 8 8 8 8 8 8 9 9 9] - prediction [4] label: 8 \n",
            "Avg Training Loss: 2.356378828585148 Avg Train Accuracy: 0.26470000002533195\n",
            "\n",
            "Epoch 4\n",
            "Batch 0 Sequence: [7 7 7 8 8 8 8 8 8 8] - prediction [7] label: 7 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [4] label: 6 Batch 200 Sequence: [5 5 5 5 6 6 6 6 6 6] - prediction [2] label: 6 Batch 300 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.3220735174417495 Avg Train Accuracy: 0.2997000012919307\n",
            "\n",
            "Epoch 5\n",
            "Batch 0 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [4] label: 5 Batch 100 Sequence: [8 8 9 9 9 9 9 9 9 9] - prediction [4] label: 8 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 300 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [4] label: 5 \n",
            "Avg Training Loss: 2.3135999029874803 Avg Train Accuracy: 0.2708000004477799\n",
            "\n",
            "Epoch 6\n",
            "Batch 0 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [8] label: 6 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 200 Sequence: [8 9 9 9 9 9 9 9 9 9] - prediction [4] label: 0 Batch 300 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [7] label: 8 \n",
            "Avg Training Loss: 2.386829722672701 Avg Train Accuracy: 0.29320000115782024\n",
            "\n",
            "Epoch 7\n",
            "Batch 0 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [7] label: 6 Batch 100 Sequence: [9 9 9 9 1 2 2 3 3 3] - prediction [7] label: 3 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [7] label: 4 Batch 300 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [7] label: 5 \n",
            "Avg Training Loss: 2.3264538127183916 Avg Train Accuracy: 0.2786999999731779\n",
            "\n",
            "Epoch 8\n",
            "Batch 0 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [4] label: 5 Batch 100 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [4] label: 5 Batch 200 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [5] label: 4 Batch 300 Sequence: [9 9 9 9 9 9 1 2 2 3] - prediction [6] label: 2 \n",
            "Avg Training Loss: 2.4429456874728204 Avg Train Accuracy: 0.26610000010579826\n",
            "\n",
            "Epoch 9\n",
            "Batch 0 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 100 Sequence: [4 4 4 4 5 5 5 5 5 6] - prediction [4] label: 5 Batch 200 Sequence: [9 9 1 2 2 3 3 3 4 4] - prediction [5] label: 3 Batch 300 Sequence: [6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.3357964831590654 Avg Train Accuracy: 0.28690000077709554\n",
            "\n",
            "Epoch 10\n",
            "Batch 0 Sequence: [4 4 5 5 5 5 5 6 6 6] - prediction [4] label: 5 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [4] label: 5 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 300 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [7] label: 5 \n",
            "Avg Training Loss: 2.2479037879407406 Avg Train Accuracy: 0.32220000298693774\n",
            "\n",
            "Epoch 11\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [6] label: 8 Batch 100 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [4] label: 6 Batch 200 Sequence: [5 5 6 6 6 6 6 6 7 7] - prediction [8] label: 6 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.3888251201808455 Avg Train Accuracy: 0.2839000006392598\n",
            "\n",
            "Epoch 12\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [6] label: 5 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 200 Sequence: [5 5 6 6 6 6 6 6 7 7] - prediction [4] label: 6 Batch 300 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [7] label: 6 \n",
            "Avg Training Loss: 2.3828139585256576 Avg Train Accuracy: 0.27860000044107436\n",
            "\n",
            "Epoch 13\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [4] label: 8 Batch 100 Sequence: [9 9 9 9 9 1 2 2 3 3] - prediction [5] label: 2 Batch 200 Sequence: [9 9 9 9 9 9 9 1 2 2] - prediction [5] label: 2 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [3] label: 4 \n",
            "Avg Training Loss: 2.344164276123047 Avg Train Accuracy: 0.2805000001378357\n",
            "\n",
            "Epoch 14\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 9 9 1 2] - prediction [4] label: 1 Batch 100 Sequence: [9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 Batch 200 Sequence: [7 7 7 7 8 8 8 8 8 8] - prediction [4] label: 7 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [8] label: 4 \n",
            "Avg Training Loss: 2.318305412828922 Avg Train Accuracy: 0.2924000007659197\n",
            "\n",
            "Epoch 15\n",
            "Batch 0 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [4] label: 4 Batch 100 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [4] label: 5 Batch 200 Sequence: [5 5 5 5 6 6 6 6 6 6] - prediction [2] label: 6 Batch 300 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [7] label: 6 \n",
            "Avg Training Loss: 2.346721179485321 Avg Train Accuracy: 0.3085000024922192\n",
            "\n",
            "Epoch 16\n",
            "Batch 0 Sequence: [9 9 9 9 9 1 2 2 3 3] - prediction [4] label: 2 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [6] label: 4 Batch 200 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [5] label: 6 Batch 300 Sequence: [6 6 6 6 7 7 7 7 7 7] - prediction [6] label: 6 \n",
            "Avg Training Loss: 2.4405958077311514 Avg Train Accuracy: 0.2835000011883676\n",
            "\n",
            "Epoch 17\n",
            "Batch 0 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [4] label: 6 Batch 100 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [4] label: 6 Batch 200 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [7] label: 5 Batch 300 Sequence: [7 7 7 7 7 8 8 8 8 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.370500635802746 Avg Train Accuracy: 0.2727000009454787\n",
            "\n",
            "Epoch 18\n",
            "Batch 0 Sequence: [6 6 6 6 7 7 7 7 7 7] - prediction [7] label: 6 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 200 Sequence: [4 4 5 5 5 5 5 6 6 6] - prediction [7] label: 5 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.3166800871491433 Avg Train Accuracy: 0.2737000005505979\n",
            "\n",
            "Epoch 19\n",
            "Batch 0 Sequence: [8 8 8 8 9 9 9 9 9 9] - prediction [7] label: 8 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [8] label: 4 Batch 200 Sequence: [4 4 4 4 5 5 5 5 5 6] - prediction [4] label: 5 Batch 300 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [1] label: 5 \n",
            "Avg Training Loss: 2.325556921958923 Avg Train Accuracy: 0.3025000011734664\n",
            "\n",
            "Epoch 20\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 8 8 9 9] - prediction [7] label: 8 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 300 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [4] label: 6 \n",
            "Avg Training Loss: 2.38409288585186 Avg Train Accuracy: 0.2876000007800758\n",
            "\n",
            "Epoch 21\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 9 9 9 1] - prediction [4] label: 1 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [7] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [7] label: 4 Batch 300 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.479255324304104 Avg Train Accuracy: 0.29100000083446503\n",
            "\n",
            "Epoch 22\n",
            "Batch 0 Sequence: [7 7 7 7 7 7 7 8 8 8] - prediction [4] label: 7 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [5] label: 4 Batch 200 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.3445622040331364 Avg Train Accuracy: 0.3008000012114644\n",
            "\n",
            "Epoch 23\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 8 9 9 9] - prediction [4] label: 8 Batch 100 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [6] label: 7 Batch 200 Sequence: [7 7 7 8 8 8 8 8 8 8] - prediction [6] label: 7 Batch 300 Sequence: [9 9 9 1 2 2 3 3 3 4] - prediction [4] label: 3 \n",
            "Avg Training Loss: 2.3817891749739646 Avg Train Accuracy: 0.2655999997444451\n",
            "\n",
            "Epoch 24\n",
            "Batch 0 Sequence: [8 9 9 9 9 9 9 9 9 9] - prediction [4] label: 0 Batch 100 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [7] label: 6 Batch 200 Sequence: [7 7 7 7 7 7 7 8 8 8] - prediction [4] label: 7 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [8] label: 4 \n",
            "Avg Training Loss: 2.3233764231204987 Avg Train Accuracy: 0.29380000170320275\n",
            "\n",
            "Epoch 25\n",
            "Batch 0 Sequence: [9 9 9 9 1 2 2 3 3 3] - prediction [4] label: 3 Batch 100 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [8] label: 6 Batch 200 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [4] label: 5 Batch 300 Sequence: [4 4 4 4 5 5 5 5 5 6] - prediction [8] label: 5 \n",
            "Avg Training Loss: 2.3877669304609297 Avg Train Accuracy: 0.3068000020831823\n",
            "\n",
            "Epoch 26\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [4] label: 5 Batch 100 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [5] label: 4 Batch 200 Sequence: [8 8 8 8 9 9 9 9 9 9] - prediction [7] label: 8 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.3799489486217498 Avg Train Accuracy: 0.28070000030100345\n",
            "\n",
            "Epoch 27\n",
            "Batch 0 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [4] label: 8 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [7] label: 5 Batch 200 Sequence: [4 4 5 5 5 5 5 6 6 6] - prediction [4] label: 5 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.439690836369991 Avg Train Accuracy: 0.26509999990463257\n",
            "\n",
            "Epoch 28\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 200 Sequence: [9 9 1 2 2 3 3 3 4 4] - prediction [4] label: 3 Batch 300 Sequence: [7 8 8 8 8 8 8 8 8 9] - prediction [4] label: 8 \n",
            "Avg Training Loss: 2.4179424926638604 Avg Train Accuracy: 0.27039999986067415\n",
            "\n",
            "Epoch 29\n",
            "Batch 0 Sequence: [4 4 5 5 5 5 5 6 6 6] - prediction [3] label: 5 Batch 100 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [6] label: 8 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 300 Sequence: [7 7 7 7 7 7 8 8 8 8] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.381848165690899 Avg Train Accuracy: 0.3004000016488135\n",
            "\n",
            "Epoch 30\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [8] label: 5 Batch 200 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [4] label: 5 Batch 300 Sequence: [5 5 6 6 6 6 6 6 7 7] - prediction [7] label: 6 \n",
            "Avg Training Loss: 2.3607189486920834 Avg Train Accuracy: 0.29740000143647194\n",
            "\n",
            "Epoch 31\n",
            "Batch 0 Sequence: [7 7 7 8 8 8 8 8 8 8] - prediction [1] label: 7 Batch 100 Sequence: [8 8 8 8 8 8 8 9 9 9] - prediction [4] label: 8 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [5] label: 4 Batch 300 Sequence: [7 7 7 7 7 8 8 8 8 8] - prediction [2] label: 7 \n",
            "Avg Training Loss: 2.3534566307067872 Avg Train Accuracy: 0.2900000006891787\n",
            "\n",
            "Epoch 32\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [4] label: 4 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 200 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [6] label: 8 Batch 300 Sequence: [7 7 7 7 7 7 8 8 8 8] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.378807223141193 Avg Train Accuracy: 0.3001000014692545\n",
            "\n",
            "Epoch 33\n",
            "Batch 0 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [4] label: 7 Batch 100 Sequence: [9 9 9 9 9 9 9 9 9 1] - prediction [4] label: 1 Batch 200 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [3] label: 5 Batch 300 Sequence: [6 6 6 6 7 7 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.3532023566961286 Avg Train Accuracy: 0.2831000010855496\n",
            "\n",
            "Epoch 34\n",
            "Batch 0 Sequence: [5 5 6 6 6 6 6 6 7 7] - prediction [5] label: 6 Batch 100 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [4] label: 8 Batch 200 Sequence: [9 9 9 9 1 2 2 3 3 3] - prediction [4] label: 3 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.364023158699274 Avg Train Accuracy: 0.29480000061914324\n",
            "\n",
            "Epoch 35\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 100 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [5] label: 4 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [6] label: 4 Batch 300 Sequence: [4 4 4 5 5 5 5 5 6 6] - prediction [7] label: 5 \n",
            "Avg Training Loss: 2.4038523524999618 Avg Train Accuracy: 0.2792000006511807\n",
            "\n",
            "Epoch 36\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [6] label: 4 Batch 100 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [5] label: 8 Batch 200 Sequence: [7 7 7 8 8 8 8 8 8 8] - prediction [5] label: 7 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.387768681049347 Avg Train Accuracy: 0.27760000072419644\n",
            "\n",
            "Epoch 37\n",
            "Batch 0 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 Batch 100 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 200 Sequence: [9 9 9 9 9 9 1 2 2 3] - prediction [2] label: 2 Batch 300 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [8] label: 4 \n",
            "Avg Training Loss: 2.3756385520100594 Avg Train Accuracy: 0.27730000028386714\n",
            "\n",
            "Epoch 38\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 100 Sequence: [6 6 6 7 7 7 7 7 7 7] - prediction [4] label: 7 Batch 200 Sequence: [9 9 9 9 9 1 2 2 3 3] - prediction [4] label: 2 Batch 300 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [8] label: 6 \n",
            "Avg Training Loss: 2.386695819795132 Avg Train Accuracy: 0.2602000005915761\n",
            "\n",
            "Epoch 39\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 8 8 9 9] - prediction [8] label: 8 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [6] label: 4 Batch 200 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [4] label: 6 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.361656592488289 Avg Train Accuracy: 0.2828000008873641\n",
            "\n",
            "Epoch 40\n",
            "Batch 0 Sequence: [8 8 8 8 8 9 9 9 9 9] - prediction [8] label: 8 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [4] label: 6 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 300 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [4] label: 5 \n",
            "Avg Training Loss: 2.389095416069031 Avg Train Accuracy: 0.2669999998435378\n",
            "\n",
            "Epoch 41\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [6] label: 4 Batch 100 Sequence: [7 7 7 7 8 8 8 8 8 8] - prediction [4] label: 7 Batch 200 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [4] label: 4 Batch 300 Sequence: [8 9 9 9 9 9 9 9 9 9] - prediction [4] label: 0 \n",
            "Avg Training Loss: 2.307078941464424 Avg Train Accuracy: 0.3126000022701919\n",
            "\n",
            "Epoch 42\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 100 Sequence: [8 8 8 8 8 8 8 9 9 9] - prediction [5] label: 8 Batch 200 Sequence: [5 5 5 5 6 6 6 6 6 6] - prediction [8] label: 6 Batch 300 Sequence: [9 9 9 9 9 9 9 1 2 2] - prediction [7] label: 2 \n",
            "Avg Training Loss: 2.3591357116401195 Avg Train Accuracy: 0.29900000190362336\n",
            "\n",
            "Epoch 43\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [4] label: 5 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 200 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [4] label: 6 Batch 300 Sequence: [5 5 5 5 6 6 6 6 6 6] - prediction [8] label: 6 \n",
            "Avg Training Loss: 2.400432959794998 Avg Train Accuracy: 0.2750000006519258\n",
            "\n",
            "Epoch 44\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [4] label: 4 Batch 100 Sequence: [8 8 8 8 8 8 8 9 9 9] - prediction [3] label: 8 Batch 200 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 Batch 300 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [6] label: 4 \n",
            "Avg Training Loss: 2.351992212980986 Avg Train Accuracy: 0.29060000136494635\n",
            "\n",
            "Epoch 45\n",
            "Batch 0 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [7] label: 7 Batch 100 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [4] label: 5 Batch 200 Sequence: [8 8 8 8 9 9 9 9 9 9] - prediction [4] label: 8 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.255749996304512 Avg Train Accuracy: 0.2879000001400709\n",
            "\n",
            "Epoch 46\n",
            "Batch 0 Sequence: [9 1 2 2 3 3 3 4 4 4] - prediction [4] label: 3 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [7] label: 5 Batch 200 Sequence: [7 7 7 7 7 8 8 8 8 8] - prediction [4] label: 7 Batch 300 Sequence: [8 8 8 8 8 9 9 9 9 9] - prediction [8] label: 8 \n",
            "Avg Training Loss: 2.4215272441506386 Avg Train Accuracy: 0.277100000102073\n",
            "\n",
            "Epoch 47\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [7] label: 4 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [6] label: 4 Batch 200 Sequence: [5 5 6 6 6 6 6 6 7 7] - prediction [4] label: 6 Batch 300 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [4] label: 8 \n",
            "Avg Training Loss: 2.4142193022370337 Avg Train Accuracy: 0.2849000003747642\n",
            "\n",
            "Epoch 48\n",
            "Batch 0 Sequence: [5 5 5 6 6 6 6 6 6 7] - prediction [4] label: 6 Batch 100 Sequence: [8 8 9 9 9 9 9 9 9 9] - prediction [7] label: 8 Batch 200 Sequence: [9 9 9 9 9 9 9 1 2 2] - prediction [4] label: 2 Batch 300 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.379731879234314 Avg Train Accuracy: 0.2924000017717481\n",
            "\n",
            "Epoch 49\n",
            "Batch 0 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [4] label: 6 Batch 100 Sequence: [7 7 7 7 8 8 8 8 8 8] - prediction [5] label: 7 Batch 200 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [4] label: 4 Batch 300 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [6] label: 8 \n",
            "Avg Training Loss: 2.325281102657318 Avg Train Accuracy: 0.28880000084638596\n",
            "\n",
            "Epoch 50\n",
            "Batch 0 Sequence: [8 8 8 8 9 9 9 9 9 9] - prediction [5] label: 8 Batch 100 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [4] label: 8 Batch 200 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [4] label: 4 Batch 300 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [4] label: 6 \n",
            "Avg Training Loss: 2.404590282589197 Avg Train Accuracy: 0.3087000023573637\n",
            "\n",
            "Epoch 51\n",
            "Batch 0 Sequence: [7 7 7 7 8 8 8 8 8 8] - prediction [4] label: 7 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [8] label: 4 Batch 200 Sequence: [6 6 6 7 7 7 7 7 7 7] - prediction [8] label: 7 Batch 300 Sequence: [4 4 4 4 5 5 5 5 5 6] - prediction [4] label: 5 \n",
            "Avg Training Loss: 2.273124354928732 Avg Train Accuracy: 0.329100002925843\n",
            "\n",
            "Epoch 52\n",
            "Batch 0 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [6] label: 7 Batch 100 Sequence: [5 5 5 5 6 6 6 6 6 6] - prediction [4] label: 6 Batch 200 Sequence: [8 8 8 8 8 9 9 9 9 9] - prediction [6] label: 8 Batch 300 Sequence: [6 6 6 7 7 7 7 7 7 7] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.3443237560987473 Avg Train Accuracy: 0.2981000014021993\n",
            "\n",
            "Epoch 53\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [6] label: 4 Batch 100 Sequence: [9 9 9 9 9 9 9 9 9 1] - prediction [4] label: 1 Batch 200 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [5] label: 4 Batch 300 Sequence: [6 6 6 6 6 6 7 7 7 7] - prediction [6] label: 6 \n",
            "Avg Training Loss: 2.406950808763504 Avg Train Accuracy: 0.28650000086054206\n",
            "\n",
            "Epoch 54\n",
            "Batch 0 Sequence: [8 8 8 9 9 9 9 9 9 9] - prediction [6] label: 8 Batch 100 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 Batch 200 Sequence: [8 8 8 8 8 8 8 8 9 9] - prediction [4] label: 8 Batch 300 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.4106031346321104 Avg Train Accuracy: 0.2767000008560717\n",
            "\n",
            "Epoch 55\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 9 1 2 2] - prediction [4] label: 2 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [6] label: 4 Batch 200 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [8] label: 8 Batch 300 Sequence: [7 8 8 8 8 8 8 8 8 9] - prediction [4] label: 8 \n",
            "Avg Training Loss: 2.3860354742407797 Avg Train Accuracy: 0.28700000021606686\n",
            "\n",
            "Epoch 56\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5] - prediction [4] label: 4 Batch 100 Sequence: [9 9 9 9 1 2 2 3 3 3] - prediction [4] label: 3 Batch 200 Sequence: [5 5 5 5 6 6 6 6 6 6] - prediction [4] label: 6 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.3608243906497957 Avg Train Accuracy: 0.26840000024065375\n",
            "\n",
            "Epoch 57\n",
            "Batch 0 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 100 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [4] label: 5 Batch 200 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [5] label: 4 Batch 300 Sequence: [9 9 9 9 9 9 9 9 9 1] - prediction [4] label: 1 \n",
            "Avg Training Loss: 2.3526672679185867 Avg Train Accuracy: 0.28160000070929525\n",
            "\n",
            "Epoch 58\n",
            "Batch 0 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [6] label: 5 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [7] label: 4 Batch 200 Sequence: [6 7 7 7 7 7 7 7 8 8] - prediction [3] label: 7 Batch 300 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.3378108859062197 Avg Train Accuracy: 0.3079000012949109\n",
            "\n",
            "Epoch 59\n",
            "Batch 0 Sequence: [8 8 8 8 8 9 9 9 9 9] - prediction [4] label: 8 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 200 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [6] label: 8 Batch 300 Sequence: [8 9 9 9 9 9 9 9 9 9] - prediction [4] label: 0 \n",
            "Avg Training Loss: 2.378757036626339 Avg Train Accuracy: 0.2773000001348555\n",
            "\n",
            "Epoch 60\n",
            "Batch 0 Sequence: [7 8 8 8 8 8 8 8 8 9] - prediction [5] label: 8 Batch 100 Sequence: [9 9 9 9 9 1 2 2 3 3] - prediction [5] label: 2 Batch 200 Sequence: [8 8 8 8 8 8 8 9 9 9] - prediction [8] label: 8 Batch 300 Sequence: [4 5 5 5 5 5 6 6 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.3640738290548327 Avg Train Accuracy: 0.29250000026077033\n",
            "\n",
            "Epoch 61\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 9 1 2 2] - prediction [4] label: 2 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7] - prediction [2] label: 6 Batch 200 Sequence: [7 8 8 8 8 8 8 8 8 9] - prediction [4] label: 8 Batch 300 Sequence: [8 8 9 9 9 9 9 9 9 9] - prediction [4] label: 8 \n",
            "Avg Training Loss: 2.376196179240942 Avg Train Accuracy: 0.29410000137984754\n",
            "\n",
            "Epoch 62\n",
            "Batch 0 Sequence: [5 5 5 6 6 6 6 6 6 7] - prediction [5] label: 6 Batch 100 Sequence: [9 9 9 9 9 9 1 2 2 3] - prediction [5] label: 2 Batch 200 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [5] label: 4 Batch 300 Sequence: [6 6 6 7 7 7 7 7 7 7] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.3405690759420397 Avg Train Accuracy: 0.2799000008590519\n",
            "\n",
            "Epoch 63\n",
            "Batch 0 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [6] label: 6 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5] - prediction [4] label: 4 Batch 300 Sequence: [9 9 9 9 9 9 9 1 2 2] - prediction [4] label: 2 \n",
            "Avg Training Loss: 2.417975563108921 Avg Train Accuracy: 0.2953000015579164\n",
            "\n",
            "Epoch 64\n",
            "Batch 0 Sequence: [7 7 7 7 7 7 7 8 8 8] - prediction [7] label: 7 Batch 100 Sequence: [8 8 8 8 8 8 9 9 9 9] - prediction [6] label: 8 Batch 200 Sequence: [8 8 8 9 9 9 9 9 9 9] - prediction [7] label: 8 Batch 300 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.317154523432255 Avg Train Accuracy: 0.3004000007919967\n",
            "\n",
            "Epoch 65\n",
            "Batch 0 Sequence: [7 7 7 8 8 8 8 8 8 8] - prediction [4] label: 7 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5] - prediction [4] label: 4 Batch 200 Sequence: [4 4 5 5 5 5 5 6 6 6] - prediction [4] label: 5 Batch 300 Sequence: [6 6 6 6 7 7 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.456213826239109 Avg Train Accuracy: 0.2626999997347593\n",
            "\n",
            "Epoch 66\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [4] label: 4 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [8] label: 4 Batch 300 Sequence: [3 4 4 4 4 5 5 5 5 5] - prediction [1] label: 5 \n",
            "Avg Training Loss: 2.4461233049631117 Avg Train Accuracy: 0.27500000027939675\n",
            "\n",
            "Epoch 67\n",
            "Batch 0 Sequence: [9 9 9 9 1 2 2 3 3 3] - prediction [8] label: 3 Batch 100 Sequence: [8 8 8 8 9 9 9 9 9 9] - prediction [4] label: 8 Batch 200 Sequence: [5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 300 Sequence: [8 8 8 8 8 8 8 8 9 9] - prediction [4] label: 8 \n",
            "Avg Training Loss: 2.358154365718365 Avg Train Accuracy: 0.28300000101327893\n",
            "\n",
            "Epoch 68\n",
            "Batch 0 Sequence: [3 3 4 4 4 4 5 5 5 5] - prediction [6] label: 4 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 200 Sequence: [9 9 9 9 9 9 1 2 2 3] - prediction [4] label: 2 Batch 300 Sequence: [8 8 8 9 9 9 9 9 9 9] - prediction [7] label: 8 \n",
            "Avg Training Loss: 2.401385125219822 Avg Train Accuracy: 0.27450000075623393\n",
            "\n",
            "Epoch 69\n",
            "Batch 0 Sequence: [6 6 6 6 6 7 7 7 7 7] - prediction [4] label: 6 Batch 100 Sequence: [9 9 9 9 9 1 2 2 3 3] - prediction [4] label: 2 Batch 200 Sequence: [7 7 8 8 8 8 8 8 8 8] - prediction [5] label: 8 Batch 300 Sequence: [9 9 9 9 9 1 2 2 3 3] - prediction [5] label: 2 \n",
            "Avg Training Loss: 2.2250440335273742 Avg Train Accuracy: 0.3149000018276274\n",
            "\n",
            "Final Test Loss: 2.305594688653946 Final Test Accuracy: 0.11199999749660491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kLBc-8WDZDmo",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $1.5$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "_F9wjk3lZDmq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 2.4. Questions\n",
        "\n",
        "a) What will happen to the test performance, if we trained the model with a sequence size of 3 or 15? Thereby, consider the generation of the sequences. (**1 point**)\n",
        "\n",
        "**Ans** Generally, decreasing the sequence length results in a worse perform becasue the model does not have enough context to make a correct prediction and it will just  predict words that occur frequently in the corpus. \n",
        "However, in this case a sequence length of 3 resuls in a better performance becasue of the nature of the sequence. If the sequence ends with a number greater than 3, the RNN has to predict the same number to be correct. \n",
        "By increasing the sequence length, we the accuracy to improves, but not by a wide margin because RNNs are not good at encoding long range dependencies.\n",
        "\n",
        "b) Actually we are just considering fixed sized vectors as input and apply a classification on them. Does this mean that we could also train a Fully Connected Neural Network or an SVM for this problem? Which would be more efficient and why? Briefly explain your answer. (**1 point**)\n",
        "\n",
        "**Ans** RNN builds the sequence representation step by step, which is not the same as classifying fixed sized vectors. The latter is analogous to doing prediction with an n-gram language model with a large n, in which case performance would be bad because of data sparsity. The performance would remain more or less bad regardless of which model is used if the input is represented like this.\n",
        "\n",
        "We can use a CNN for this problem, the kernels would slide across the input and amount of context encoded in the representation would depend on the kernel size (note that both the left and right context would be considered). If the kernel size is relatively small, this model would be more efficient because parameters are shared in the network. But if one wants to include large context, that would make the CNN really slow ad inefficient compared to the RNN."
      ]
    },
    {
      "metadata": {
        "id": "98ySCNkaeSnC",
        "colab_type": "code",
        "outputId": "1cd1e356-6e7a-48b6-f072-763ce0fdb789",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5050
        }
      },
      "cell_type": "code",
      "source": [
        "#sequence_size = 3\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.01\n",
        "epochs = 70\n",
        "batch_size = 5\n",
        "\n",
        "# length of a single sequence\n",
        "input_seq_len = 3\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 90\n",
        "\n",
        "n_vocab=9\n",
        "\n",
        "\n",
        "RNN_graph = tf.Graph()\n",
        "with RNN_graph.as_default():\n",
        "\n",
        "    # tf Graph input: X = sequences, Y = digits to predict \n",
        "    batchX_placeholder = tf.placeholder(tf.int32, [batch_size, input_seq_len])\n",
        "    batchY_placeholder = tf.placeholder(tf.int32, [batch_size, 1])\n",
        "\n",
        "    # init_state = h0\n",
        "    init_state = tf.Variable(tf.random_normal([batch_size, n_hidden]))\n",
        "\n",
        "    # TODO: RNN output node weights and biases - set the tf.Variables with correct shapes and random_normal initialization\n",
        "    weights = {\n",
        "        'U': tf.Variable(np.random.rand(n_vocab,n_hidden), dtype=tf.float32),\n",
        "        'W': tf.Variable(np.random.rand(n_hidden, n_hidden), dtype=tf.float32),\n",
        "        'V': tf.Variable(np.random.rand(n_hidden, n_vocab), dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    biases = {\n",
        "        'b': tf.Variable(np.zeros((1,n_hidden)), dtype=tf.float32),\n",
        "        'c': tf.Variable(np.zeros((1,n_vocab)), dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    # TODO: setup graph for the RNN\n",
        "    inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
        "    labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
        "    labels = tf.one_hot(labels_series,depth=n_vocab)\n",
        "    \n",
        "    h_prev = init_state\n",
        "    states = []\n",
        "    for t in range(input_seq_len):\n",
        "#       input_t = tf.reshape(input_series[t], [batch_size, 1])\n",
        "      x_t = tf.one_hot(inputs_series[t], depth=n_vocab)\n",
        "      a_t = tf.matmul(h_prev,weights['W']) + tf.matmul(x_t,weights['U']) +biases['b']\n",
        "      h_t = tf.tanh(a_t)\n",
        "      states.append(h_t)\n",
        "      h_prev = h_t\n",
        "    \n",
        "    # TODO: network output\n",
        "    \n",
        "    o = tf.matmul(h_t,weights['V'])+biases['c']\n",
        "    predictions = tf.nn.softmax(o)\n",
        "\n",
        "    # class predictions\n",
        "    predictions = tf.argmax(o, axis=1)\n",
        "    predictions = tf.reshape(predictions, [-1, 1])\n",
        "\n",
        "    # TODO: accuracy \n",
        "    correct_prediction = tf.equal(predictions,labels_series)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # TODO: loss of the current batch\n",
        "    total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels,logits=o))\n",
        "    train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(total_loss)\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = generate_dataset(sample_count=2000,sample_size=3)\n",
        "X_test, y_test = generate_dataset(sample_count=100,sample_size=3)\n",
        "\n",
        "num_batches = len(X_train) // batch_size\n",
        "\n",
        "# Launch the Session\n",
        "with tf.Session(graph=RNN_graph) as session:\n",
        "\n",
        "    # label shift for loss computation\n",
        "    y_train = y_train - 1\n",
        "    \n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    session.run(init)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "\n",
        "        print(\"\\nEpoch {}\".format(cur_epoch))\n",
        "        acc_sum = 0\n",
        "        loss_sum = 0\n",
        "\n",
        "        indices = np.random.permutation(len(X_train))\n",
        "\n",
        "        for cur_batch_count in range(num_batches):\n",
        "\n",
        "            batch_indices = np.array(indices[cur_batch_count:cur_batch_count + batch_size])\n",
        "\n",
        "            x_batch = X_train[batch_indices]\n",
        "            y_batch = y_train[batch_indices]    \n",
        "            \n",
        "            preds, cur_loss, cur_acc, _ = session.run([predictions, total_loss, accuracy, train_step], feed_dict={batchX_placeholder: x_batch, \n",
        "                                                                                    batchY_placeholder: np.reshape(y_batch, [batch_size, 1])\n",
        "                                                                                    })\n",
        "            acc_sum += cur_acc\n",
        "            loss_sum += cur_loss\n",
        "            \n",
        "            # TODO: Implement the printing of the current batch predictions for batch 0, 100, 200, etc.\n",
        "            if cur_batch_count%100 ==0:\n",
        "              print('Batch '+ str(cur_batch_count), end=\"\")\n",
        "              for i in range(batch_size):\n",
        "                s=(' Sequence: {} - prediction {} label: {} ').format(x_batch[i],preds[i],y_batch[i])\n",
        "              print(s,end=\"\")\n",
        "            \n",
        "            \n",
        "        print(\"\\nAvg Training Loss: {} Avg Train Accuracy: {}\".format(loss_sum / num_batches, acc_sum / num_batches))\n",
        "        \n",
        "    # Testing\n",
        "    num_batches = len(X_test) // batch_size\n",
        "    y_test = y_test - 1\n",
        "\n",
        "    acc_sum = 0\n",
        "    loss_sum = 0\n",
        "\n",
        "    for cur_batch_count in range(num_batches):\n",
        "        x_batch = X_test[cur_batch_count:cur_batch_count+batch_size]\n",
        "        y_batch = y_test[cur_batch_count:cur_batch_count+batch_size]            \n",
        "\n",
        "        cur_loss, cur_acc = session.run([total_loss, accuracy], feed_dict={batchX_placeholder: x_batch, \n",
        "                                                                           batchY_placeholder: np.reshape(y_batch, [batch_size, 1])\n",
        "                                                                           })\n",
        "\n",
        "        acc_sum += cur_acc\n",
        "        loss_sum += cur_loss\n",
        "\n",
        "    print(\"\\nFinal Test Loss: {} Final Test Accuracy: {}\".format(loss_sum / num_batches, acc_sum / num_batches))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0\n",
            "Batch 0 Sequence: [5 5 6] - prediction [4] label: 5 Batch 100 Sequence: [8 8 8] - prediction [8] label: 7 Batch 200 Sequence: [3 3 3] - prediction [6] label: 3 Batch 300 Sequence: [1 2 2] - prediction [3] label: 2 \n",
            "Avg Training Loss: 2.385942150056362 Avg Train Accuracy: 0.24829999793320895\n",
            "\n",
            "Epoch 1\n",
            "Batch 0 Sequence: [9 9 9] - prediction [2] label: 8 Batch 100 Sequence: [1 2 2] - prediction [7] label: 2 Batch 200 Sequence: [2 3 3] - prediction [5] label: 2 Batch 300 Sequence: [3 4 4] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.2996459916234016 Avg Train Accuracy: 0.26779999924823644\n",
            "\n",
            "Epoch 2\n",
            "Batch 0 Sequence: [8 8 8] - prediction [8] label: 7 Batch 100 Sequence: [1 2 2] - prediction [2] label: 2 Batch 200 Sequence: [8 8 8] - prediction [2] label: 7 Batch 300 Sequence: [3 4 4] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.3024367809295656 Avg Train Accuracy: 0.27209999952465297\n",
            "\n",
            "Epoch 3\n",
            "Batch 0 Sequence: [3 3 3] - prediction [2] label: 3 Batch 100 Sequence: [5 5 6] - prediction [2] label: 5 Batch 200 Sequence: [4 4 4] - prediction [8] label: 3 Batch 300 Sequence: [5 6 6] - prediction [6] label: 5 \n",
            "Avg Training Loss: 2.4324489238858225 Avg Train Accuracy: 0.24949999982491136\n",
            "\n",
            "Epoch 4\n",
            "Batch 0 Sequence: [6 6 6] - prediction [2] label: 5 Batch 100 Sequence: [2 2 3] - prediction [4] label: 2 Batch 200 Sequence: [8 8 8] - prediction [3] label: 8 Batch 300 Sequence: [1 2 2] - prediction [8] label: 2 \n",
            "Avg Training Loss: 2.3157988311350346 Avg Train Accuracy: 0.2579999991320074\n",
            "\n",
            "Epoch 5\n",
            "Batch 0 Sequence: [4 4 4] - prediction [4] label: 3 Batch 100 Sequence: [4 4 5] - prediction [2] label: 4 Batch 200 Sequence: [3 3 4] - prediction [2] label: 3 Batch 300 Sequence: [3 3 4] - prediction [3] label: 3 \n",
            "Avg Training Loss: 2.3425671914219857 Avg Train Accuracy: 0.25519999949261546\n",
            "\n",
            "Epoch 6\n",
            "Batch 0 Sequence: [8 8 8] - prediction [1] label: 8 Batch 100 Sequence: [6 6 6] - prediction [5] label: 5 Batch 200 Sequence: [6 6 6] - prediction [6] label: 5 Batch 300 Sequence: [8 9 9] - prediction [7] label: 8 \n",
            "Avg Training Loss: 2.3491599050164225 Avg Train Accuracy: 0.2659999996982515\n",
            "\n",
            "Epoch 7\n",
            "Batch 0 Sequence: [9 9 9] - prediction [2] label: 0 Batch 100 Sequence: [2 2 3] - prediction [2] label: 2 Batch 200 Sequence: [7 7 7] - prediction [4] label: 6 Batch 300 Sequence: [4 4 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.358213971555233 Avg Train Accuracy: 0.2668999982625246\n",
            "\n",
            "Epoch 8\n",
            "Batch 0 Sequence: [6 6 6] - prediction [3] label: 5 Batch 100 Sequence: [3 3 4] - prediction [3] label: 3 Batch 200 Sequence: [4 4 4] - prediction [2] label: 3 Batch 300 Sequence: [3 4 4] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.3502398109436036 Avg Train Accuracy: 0.2698999988473952\n",
            "\n",
            "Epoch 9\n",
            "Batch 0 Sequence: [9 9 9] - prediction [3] label: 8 Batch 100 Sequence: [5 6 6] - prediction [2] label: 5 Batch 200 Sequence: [4 4 5] - prediction [3] label: 4 Batch 300 Sequence: [3 4 4] - prediction [4] label: 3 \n",
            "Avg Training Loss: 2.362081195414066 Avg Train Accuracy: 0.25539999894797805\n",
            "\n",
            "Epoch 10\n",
            "Batch 0 Sequence: [2 3 3] - prediction [2] label: 2 Batch 100 Sequence: [3 4 4] - prediction [2] label: 3 Batch 200 Sequence: [1 2 2] - prediction [2] label: 2 Batch 300 Sequence: [2 3 3] - prediction [4] label: 2 \n",
            "Avg Training Loss: 2.360302964746952 Avg Train Accuracy: 0.25589999889954923\n",
            "\n",
            "Epoch 11\n",
            "Batch 0 Sequence: [9 9 9] - prediction [7] label: 8 Batch 100 Sequence: [3 3 3] - prediction [2] label: 3 Batch 200 Sequence: [2 3 3] - prediction [8] label: 2 Batch 300 Sequence: [9 9 9] - prediction [6] label: 8 \n",
            "Avg Training Loss: 2.333930212557316 Avg Train Accuracy: 0.25589999759569765\n",
            "\n",
            "Epoch 12\n",
            "Batch 0 Sequence: [4 5 5] - prediction [2] label: 4 Batch 100 Sequence: [7 7 7] - prediction [3] label: 6 Batch 200 Sequence: [9 9 9] - prediction [8] label: 8 Batch 300 Sequence: [8 8 8] - prediction [8] label: 7 \n",
            "Avg Training Loss: 2.409087772965431 Avg Train Accuracy: 0.24379999957978726\n",
            "\n",
            "Epoch 13\n",
            "Batch 0 Sequence: [8 8 8] - prediction [6] label: 7 Batch 100 Sequence: [1 2 2] - prediction [2] label: 2 Batch 200 Sequence: [2 2 3] - prediction [6] label: 2 Batch 300 Sequence: [4 4 5] - prediction [2] label: 4 \n",
            "Avg Training Loss: 2.3779457250237463 Avg Train Accuracy: 0.24599999895319344\n",
            "\n",
            "Epoch 14\n",
            "Batch 0 Sequence: [9 9 9] - prediction [2] label: 8 Batch 100 Sequence: [8 8 8] - prediction [6] label: 7 Batch 200 Sequence: [1 2 2] - prediction [4] label: 2 Batch 300 Sequence: [4 4 4] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.373756466805935 Avg Train Accuracy: 0.2579999989271164\n",
            "\n",
            "Epoch 15\n",
            "Batch 0 Sequence: [3 3 4] - prediction [3] label: 3 Batch 100 Sequence: [9 9 9] - prediction [2] label: 8 Batch 200 Sequence: [8 8 8] - prediction [2] label: 8 Batch 300 Sequence: [3 3 4] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.341383055597544 Avg Train Accuracy: 0.27159999875351787\n",
            "\n",
            "Epoch 16\n",
            "Batch 0 Sequence: [7 7 7] - prediction [6] label: 6 Batch 100 Sequence: [8 9 9] - prediction [2] label: 8 Batch 200 Sequence: [8 8 8] - prediction [2] label: 7 Batch 300 Sequence: [7 7 8] - prediction [2] label: 7 \n",
            "Avg Training Loss: 2.31190591186285 Avg Train Accuracy: 0.2818999997712672\n",
            "\n",
            "Epoch 17\n",
            "Batch 0 Sequence: [9 9 9] - prediction [4] label: 8 Batch 100 Sequence: [1 2 2] - prediction [8] label: 2 Batch 200 Sequence: [4 4 5] - prediction [8] label: 4 Batch 300 Sequence: [1 2 2] - prediction [6] label: 2 \n",
            "Avg Training Loss: 2.398400108516216 Avg Train Accuracy: 0.2630999987386167\n",
            "\n",
            "Epoch 18\n",
            "Batch 0 Sequence: [5 6 6] - prediction [2] label: 5 Batch 100 Sequence: [2 3 3] - prediction [3] label: 2 Batch 200 Sequence: [2 2 3] - prediction [2] label: 2 Batch 300 Sequence: [5 5 5] - prediction [3] label: 4 \n",
            "Avg Training Loss: 2.3165098786354066 Avg Train Accuracy: 0.26130000058561564\n",
            "\n",
            "Epoch 19\n",
            "Batch 0 Sequence: [5 5 5] - prediction [8] label: 4 Batch 100 Sequence: [1 2 2] - prediction [7] label: 2 Batch 200 Sequence: [7 7 7] - prediction [2] label: 6 Batch 300 Sequence: [4 4 5] - prediction [6] label: 4 \n",
            "Avg Training Loss: 2.3392512169480324 Avg Train Accuracy: 0.2503999994695187\n",
            "\n",
            "Epoch 20\n",
            "Batch 0 Sequence: [7 7 7] - prediction [7] label: 6 Batch 100 Sequence: [6 7 7] - prediction [7] label: 6 Batch 200 Sequence: [3 3 3] - prediction [3] label: 3 Batch 300 Sequence: [6 6 6] - prediction [2] label: 5 \n",
            "Avg Training Loss: 2.3331642778217794 Avg Train Accuracy: 0.2605999988131225\n",
            "\n",
            "Epoch 21\n",
            "Batch 0 Sequence: [2 2 3] - prediction [6] label: 2 Batch 100 Sequence: [6 6 7] - prediction [6] label: 6 Batch 200 Sequence: [8 8 8] - prediction [3] label: 7 Batch 300 Sequence: [5 6 6] - prediction [7] label: 5 \n",
            "Avg Training Loss: 2.3665801745653154 Avg Train Accuracy: 0.25589999893680215\n",
            "\n",
            "Epoch 22\n",
            "Batch 0 Sequence: [1 2 2] - prediction [6] label: 2 Batch 100 Sequence: [2 2 3] - prediction [3] label: 2 Batch 200 Sequence: [5 6 6] - prediction [3] label: 5 Batch 300 Sequence: [8 8 8] - prediction [8] label: 7 \n",
            "Avg Training Loss: 2.349885046184063 Avg Train Accuracy: 0.2610999984294176\n",
            "\n",
            "Epoch 23\n",
            "Batch 0 Sequence: [3 3 3] - prediction [6] label: 3 Batch 100 Sequence: [6 7 7] - prediction [2] label: 6 Batch 200 Sequence: [9 9 9] - prediction [6] label: 8 Batch 300 Sequence: [1 2 2] - prediction [8] label: 2 \n",
            "Avg Training Loss: 2.3156740620732306 Avg Train Accuracy: 0.26729999992996456\n",
            "\n",
            "Epoch 24\n",
            "Batch 0 Sequence: [9 9 9] - prediction [7] label: 8 Batch 100 Sequence: [1 2 2] - prediction [2] label: 2 Batch 200 Sequence: [5 5 6] - prediction [2] label: 5 Batch 300 Sequence: [2 3 3] - prediction [6] label: 2 \n",
            "Avg Training Loss: 2.3008887684345245 Avg Train Accuracy: 0.26619999958202245\n",
            "\n",
            "Epoch 25\n",
            "Batch 0 Sequence: [4 4 4] - prediction [5] label: 4 Batch 100 Sequence: [8 8 9] - prediction [4] label: 8 Batch 200 Sequence: [1 2 2] - prediction [3] label: 2 Batch 300 Sequence: [7 7 7] - prediction [6] label: 7 \n",
            "Avg Training Loss: 2.366454232931137 Avg Train Accuracy: 0.25979999886825683\n",
            "\n",
            "Epoch 26\n",
            "Batch 0 Sequence: [8 9 9] - prediction [2] label: 8 Batch 100 Sequence: [3 4 4] - prediction [2] label: 3 Batch 200 Sequence: [9 9 9] - prediction [6] label: 8 Batch 300 Sequence: [1 2 2] - prediction [2] label: 2 \n",
            "Avg Training Loss: 2.4178694841265678 Avg Train Accuracy: 0.25489999929443\n",
            "\n",
            "Epoch 27\n",
            "Batch 0 Sequence: [6 6 6] - prediction [2] label: 5 Batch 100 Sequence: [4 4 4] - prediction [8] label: 3 Batch 200 Sequence: [3 3 3] - prediction [2] label: 3 Batch 300 Sequence: [4 4 5] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.4058829042315484 Avg Train Accuracy: 0.2407999992929399\n",
            "\n",
            "Epoch 28\n",
            "Batch 0 Sequence: [7 7 8] - prediction [7] label: 7 Batch 100 Sequence: [6 6 6] - prediction [7] label: 6 Batch 200 Sequence: [1 2 2] - prediction [2] label: 2 Batch 300 Sequence: [5 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.4182125136256216 Avg Train Accuracy: 0.24489999817684294\n",
            "\n",
            "Epoch 29\n",
            "Batch 0 Sequence: [6 6 6] - prediction [4] label: 5 Batch 100 Sequence: [6 6 6] - prediction [3] label: 5 Batch 200 Sequence: [1 2 2] - prediction [5] label: 2 Batch 300 Sequence: [2 2 3] - prediction [2] label: 2 \n",
            "Avg Training Loss: 2.3539912050962446 Avg Train Accuracy: 0.2775999985449016\n",
            "\n",
            "Epoch 30\n",
            "Batch 0 Sequence: [2 3 3] - prediction [2] label: 2 Batch 100 Sequence: [6 7 7] - prediction [6] label: 6 Batch 200 Sequence: [9 9 9] - prediction [4] label: 8 Batch 300 Sequence: [4 4 4] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.2840417143702507 Avg Train Accuracy: 0.2650999988988042\n",
            "\n",
            "Epoch 31\n",
            "Batch 0 Sequence: [2 3 3] - prediction [2] label: 2 Batch 100 Sequence: [7 7 8] - prediction [7] label: 7 Batch 200 Sequence: [5 5 5] - prediction [2] label: 4 Batch 300 Sequence: [1 2 2] - prediction [2] label: 2 \n",
            "Avg Training Loss: 2.3035177852213384 Avg Train Accuracy: 0.2827999992482364\n",
            "\n",
            "Epoch 32\n",
            "Batch 0 Sequence: [9 9 9] - prediction [8] label: 8 Batch 100 Sequence: [5 5 5] - prediction [3] label: 4 Batch 200 Sequence: [5 5 5] - prediction [3] label: 4 Batch 300 Sequence: [3 4 4] - prediction [4] label: 3 \n",
            "Avg Training Loss: 2.3286229401826857 Avg Train Accuracy: 0.2629999999143183\n",
            "\n",
            "Epoch 33\n",
            "Batch 0 Sequence: [4 4 4] - prediction [2] label: 4 Batch 100 Sequence: [5 5 5] - prediction [2] label: 4 Batch 200 Sequence: [8 8 9] - prediction [3] label: 8 Batch 300 Sequence: [2 2 3] - prediction [4] label: 2 \n",
            "Avg Training Loss: 2.3456192445755004 Avg Train Accuracy: 0.2605999989248812\n",
            "\n",
            "Epoch 34\n",
            "Batch 0 Sequence: [8 8 8] - prediction [2] label: 7 Batch 100 Sequence: [7 7 7] - prediction [3] label: 7 Batch 200 Sequence: [5 5 5] - prediction [2] label: 4 Batch 300 Sequence: [2 2 3] - prediction [6] label: 2 \n",
            "Avg Training Loss: 2.423842015564442 Avg Train Accuracy: 0.24759999867528676\n",
            "\n",
            "Epoch 35\n",
            "Batch 0 Sequence: [5 5 5] - prediction [8] label: 4 Batch 100 Sequence: [8 8 8] - prediction [7] label: 7 Batch 200 Sequence: [2 2 3] - prediction [6] label: 2 Batch 300 Sequence: [2 2 3] - prediction [3] label: 2 \n",
            "Avg Training Loss: 2.3145510801672935 Avg Train Accuracy: 0.25609999952837825\n",
            "\n",
            "Epoch 36\n",
            "Batch 0 Sequence: [5 5 6] - prediction [2] label: 5 Batch 100 Sequence: [5 5 6] - prediction [5] label: 5 Batch 200 Sequence: [1 2 2] - prediction [2] label: 2 Batch 300 Sequence: [8 8 8] - prediction [4] label: 7 \n",
            "Avg Training Loss: 2.4255340763926507 Avg Train Accuracy: 0.24869999891147018\n",
            "\n",
            "Epoch 37\n",
            "Batch 0 Sequence: [7 7 7] - prediction [4] label: 6 Batch 100 Sequence: [5 6 6] - prediction [2] label: 5 Batch 200 Sequence: [9 9 9] - prediction [2] label: 8 Batch 300 Sequence: [6 6 6] - prediction [3] label: 5 \n",
            "Avg Training Loss: 2.3759899720549584 Avg Train Accuracy: 0.25229999842122197\n",
            "\n",
            "Epoch 38\n",
            "Batch 0 Sequence: [2 3 3] - prediction [6] label: 2 Batch 100 Sequence: [5 5 5] - prediction [2] label: 4 Batch 200 Sequence: [7 7 7] - prediction [4] label: 6 Batch 300 Sequence: [4 4 5] - prediction [2] label: 4 \n",
            "Avg Training Loss: 2.3087693160772322 Avg Train Accuracy: 0.2629999984614551\n",
            "\n",
            "Epoch 39\n",
            "Batch 0 Sequence: [8 8 8] - prediction [2] label: 7 Batch 100 Sequence: [7 8 8] - prediction [2] label: 7 Batch 200 Sequence: [1 2 2] - prediction [5] label: 2 Batch 300 Sequence: [3 3 4] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.389044715762138 Avg Train Accuracy: 0.2601999991759658\n",
            "\n",
            "Epoch 40\n",
            "Batch 0 Sequence: [3 4 4] - prediction [3] label: 3 Batch 100 Sequence: [6 7 7] - prediction [3] label: 6 Batch 200 Sequence: [8 8 8] - prediction [4] label: 7 Batch 300 Sequence: [9 9 9] - prediction [2] label: 8 \n",
            "Avg Training Loss: 2.3223922581970693 Avg Train Accuracy: 0.2705999985523522\n",
            "\n",
            "Epoch 41\n",
            "Batch 0 Sequence: [8 8 8] - prediction [8] label: 7 Batch 100 Sequence: [4 5 5] - prediction [2] label: 4 Batch 200 Sequence: [4 4 4] - prediction [2] label: 3 Batch 300 Sequence: [7 7 8] - prediction [2] label: 7 \n",
            "Avg Training Loss: 2.386334990262985 Avg Train Accuracy: 0.25019999958574773\n",
            "\n",
            "Epoch 42\n",
            "Batch 0 Sequence: [1 2 2] - prediction [7] label: 2 Batch 100 Sequence: [7 7 7] - prediction [7] label: 6 Batch 200 Sequence: [3 4 4] - prediction [5] label: 3 Batch 300 Sequence: [8 8 9] - prediction [2] label: 8 \n",
            "Avg Training Loss: 2.346563061773777 Avg Train Accuracy: 0.2596999995969236\n",
            "\n",
            "Epoch 43\n",
            "Batch 0 Sequence: [3 4 4] - prediction [7] label: 3 Batch 100 Sequence: [1 2 2] - prediction [7] label: 2 Batch 200 Sequence: [7 7 7] - prediction [2] label: 6 Batch 300 Sequence: [4 5 5] - prediction [4] label: 4 \n",
            "Avg Training Loss: 2.438528062403202 Avg Train Accuracy: 0.25799999833106996\n",
            "\n",
            "Epoch 44\n",
            "Batch 0 Sequence: [5 5 6] - prediction [4] label: 5 Batch 100 Sequence: [3 3 4] - prediction [2] label: 3 Batch 200 Sequence: [9 9 9] - prediction [2] label: 8 Batch 300 Sequence: [4 4 5] - prediction [6] label: 4 \n",
            "Avg Training Loss: 2.3727166965603828 Avg Train Accuracy: 0.2536999991722405\n",
            "\n",
            "Epoch 45\n",
            "Batch 0 Sequence: [7 7 7] - prediction [4] label: 6 Batch 100 Sequence: [8 8 8] - prediction [8] label: 7 Batch 200 Sequence: [1 2 2] - prediction [3] label: 2 Batch 300 Sequence: [2 3 3] - prediction [2] label: 2 \n",
            "Avg Training Loss: 2.3394895911216738 Avg Train Accuracy: 0.25069999920204283\n",
            "\n",
            "Epoch 46\n",
            "Batch 0 Sequence: [9 9 9] - prediction [5] label: 8 Batch 100 Sequence: [8 8 8] - prediction [6] label: 7 Batch 200 Sequence: [7 7 7] - prediction [2] label: 6 Batch 300 Sequence: [2 3 3] - prediction [8] label: 2 \n",
            "Avg Training Loss: 2.338312890827656 Avg Train Accuracy: 0.2585999991185963\n",
            "\n",
            "Epoch 47\n",
            "Batch 0 Sequence: [7 7 7] - prediction [2] label: 7 Batch 100 Sequence: [6 6 6] - prediction [2] label: 5 Batch 200 Sequence: [1 2 2] - prediction [6] label: 2 Batch 300 Sequence: [3 3 3] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.3062332922220232 Avg Train Accuracy: 0.2667999988235533\n",
            "\n",
            "Epoch 48\n",
            "Batch 0 Sequence: [1 2 2] - prediction [7] label: 2 Batch 100 Sequence: [2 2 3] - prediction [2] label: 2 Batch 200 Sequence: [2 2 3] - prediction [2] label: 2 Batch 300 Sequence: [2 3 3] - prediction [3] label: 2 \n",
            "Avg Training Loss: 2.376961958408356 Avg Train Accuracy: 0.2513999989815056\n",
            "\n",
            "Epoch 49\n",
            "Batch 0 Sequence: [6 7 7] - prediction [3] label: 6 Batch 100 Sequence: [3 4 4] - prediction [3] label: 3 Batch 200 Sequence: [9 9 9] - prediction [2] label: 0 Batch 300 Sequence: [4 5 5] - prediction [2] label: 4 \n",
            "Avg Training Loss: 2.34014517724514 Avg Train Accuracy: 0.2624999987334013\n",
            "\n",
            "Epoch 50\n",
            "Batch 0 Sequence: [1 2 2] - prediction [6] label: 2 Batch 100 Sequence: [7 7 8] - prediction [2] label: 7 Batch 200 Sequence: [5 5 5] - prediction [4] label: 5 Batch 300 Sequence: [9 9 9] - prediction [2] label: 8 \n",
            "Avg Training Loss: 2.3962521597743036 Avg Train Accuracy: 0.25969999928027393\n",
            "\n",
            "Epoch 51\n",
            "Batch 0 Sequence: [5 5 5] - prediction [6] label: 4 Batch 100 Sequence: [4 4 5] - prediction [6] label: 4 Batch 200 Sequence: [1 2 2] - prediction [8] label: 2 Batch 300 Sequence: [3 3 4] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.424791001081467 Avg Train Accuracy: 0.2552999987080693\n",
            "\n",
            "Epoch 52\n",
            "Batch 0 Sequence: [3 4 4] - prediction [8] label: 3 Batch 100 Sequence: [4 4 4] - prediction [7] label: 4 Batch 200 Sequence: [8 8 8] - prediction [3] label: 8 Batch 300 Sequence: [5 5 6] - prediction [4] label: 5 \n",
            "Avg Training Loss: 2.403452081382275 Avg Train Accuracy: 0.23509999917820096\n",
            "\n",
            "Epoch 53\n",
            "Batch 0 Sequence: [2 3 3] - prediction [6] label: 2 Batch 100 Sequence: [6 6 6] - prediction [8] label: 6 Batch 200 Sequence: [9 9 9] - prediction [4] label: 8 Batch 300 Sequence: [7 7 7] - prediction [8] label: 7 \n",
            "Avg Training Loss: 2.3690063366293908 Avg Train Accuracy: 0.25969999868422744\n",
            "\n",
            "Epoch 54\n",
            "Batch 0 Sequence: [7 7 7] - prediction [2] label: 6 Batch 100 Sequence: [4 4 4] - prediction [6] label: 3 Batch 200 Sequence: [8 8 8] - prediction [2] label: 7 Batch 300 Sequence: [4 4 5] - prediction [1] label: 4 \n",
            "Avg Training Loss: 2.349218900501728 Avg Train Accuracy: 0.26789999820292\n",
            "\n",
            "Epoch 55\n",
            "Batch 0 Sequence: [2 3 3] - prediction [2] label: 2 Batch 100 Sequence: [5 5 5] - prediction [2] label: 4 Batch 200 Sequence: [3 3 3] - prediction [2] label: 3 Batch 300 Sequence: [7 7 7] - prediction [2] label: 6 \n",
            "Avg Training Loss: 2.386916551589966 Avg Train Accuracy: 0.261999998614192\n",
            "\n",
            "Epoch 56\n",
            "Batch 0 Sequence: [3 3 3] - prediction [2] label: 3 Batch 100 Sequence: [6 6 6] - prediction [2] label: 6 Batch 200 Sequence: [2 3 3] - prediction [2] label: 2 Batch 300 Sequence: [7 7 7] - prediction [4] label: 6 \n",
            "Avg Training Loss: 2.3568826296925547 Avg Train Accuracy: 0.25789999878034\n",
            "\n",
            "Epoch 57\n",
            "Batch 0 Sequence: [4 5 5] - prediction [6] label: 4 Batch 100 Sequence: [9 9 1] - prediction [2] label: 1 Batch 200 Sequence: [5 5 5] - prediction [3] label: 5 Batch 300 Sequence: [4 4 4] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.329658517837524 Avg Train Accuracy: 0.2566999989561737\n",
            "\n",
            "Epoch 58\n",
            "Batch 0 Sequence: [7 8 8] - prediction [2] label: 7 Batch 100 Sequence: [5 5 6] - prediction [2] label: 5 Batch 200 Sequence: [3 3 3] - prediction [6] label: 3 Batch 300 Sequence: [7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.336747819781303 Avg Train Accuracy: 0.25909999921917914\n",
            "\n",
            "Epoch 59\n",
            "Batch 0 Sequence: [7 7 8] - prediction [3] label: 7 Batch 100 Sequence: [3 3 3] - prediction [2] label: 3 Batch 200 Sequence: [4 4 4] - prediction [5] label: 4 Batch 300 Sequence: [5 5 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.3976594039797785 Avg Train Accuracy: 0.2568999985791743\n",
            "\n",
            "Epoch 60\n",
            "Batch 0 Sequence: [8 8 8] - prediction [2] label: 7 Batch 100 Sequence: [7 7 7] - prediction [6] label: 6 Batch 200 Sequence: [6 6 7] - prediction [2] label: 6 Batch 300 Sequence: [7 7 7] - prediction [4] label: 6 \n",
            "Avg Training Loss: 2.3979580372571947 Avg Train Accuracy: 0.25089999919757244\n",
            "\n",
            "Epoch 61\n",
            "Batch 0 Sequence: [8 8 8] - prediction [6] label: 7 Batch 100 Sequence: [1 2 2] - prediction [3] label: 2 Batch 200 Sequence: [4 5 5] - prediction [8] label: 4 Batch 300 Sequence: [3 3 3] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.408142475783825 Avg Train Accuracy: 0.25179999934509395\n",
            "\n",
            "Epoch 62\n",
            "Batch 0 Sequence: [4 4 5] - prediction [2] label: 4 Batch 100 Sequence: [6 6 6] - prediction [2] label: 5 Batch 200 Sequence: [7 7 7] - prediction [6] label: 6 Batch 300 Sequence: [9 9 9] - prediction [7] label: 8 \n",
            "Avg Training Loss: 2.3418888422846793 Avg Train Accuracy: 0.25419999901205304\n",
            "\n",
            "Epoch 63\n",
            "Batch 0 Sequence: [1 2 2] - prediction [2] label: 2 Batch 100 Sequence: [9 9 1] - prediction [5] label: 1 Batch 200 Sequence: [4 5 5] - prediction [5] label: 4 Batch 300 Sequence: [5 5 5] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.4191072303056718 Avg Train Accuracy: 0.246699999012053\n",
            "\n",
            "Epoch 64\n",
            "Batch 0 Sequence: [7 7 7] - prediction [2] label: 6 Batch 100 Sequence: [9 9 9] - prediction [3] label: 8 Batch 200 Sequence: [9 9 9] - prediction [6] label: 8 Batch 300 Sequence: [8 8 8] - prediction [2] label: 7 \n",
            "Avg Training Loss: 2.3570959466695784 Avg Train Accuracy: 0.2460999986715615\n",
            "\n",
            "Epoch 65\n",
            "Batch 0 Sequence: [6 7 7] - prediction [2] label: 6 Batch 100 Sequence: [5 5 5] - prediction [2] label: 5 Batch 200 Sequence: [3 3 4] - prediction [7] label: 3 Batch 300 Sequence: [1 2 2] - prediction [4] label: 2 \n",
            "Avg Training Loss: 2.3602189287543296 Avg Train Accuracy: 0.2629999987408519\n",
            "\n",
            "Epoch 66\n",
            "Batch 0 Sequence: [3 3 4] - prediction [5] label: 3 Batch 100 Sequence: [8 9 9] - prediction [2] label: 8 Batch 200 Sequence: [6 6 6] - prediction [2] label: 5 Batch 300 Sequence: [8 8 8] - prediction [6] label: 7 \n",
            "Avg Training Loss: 2.31078987121582 Avg Train Accuracy: 0.2746999988332391\n",
            "\n",
            "Epoch 67\n",
            "Batch 0 Sequence: [5 6 6] - prediction [3] label: 5 Batch 100 Sequence: [3 4 4] - prediction [3] label: 3 Batch 200 Sequence: [7 7 7] - prediction [5] label: 7 Batch 300 Sequence: [3 3 3] - prediction [2] label: 3 \n",
            "Avg Training Loss: 2.3963796526193617 Avg Train Accuracy: 0.25949999868869783\n",
            "\n",
            "Epoch 68\n",
            "Batch 0 Sequence: [3 4 4] - prediction [6] label: 3 Batch 100 Sequence: [3 4 4] - prediction [6] label: 3 Batch 200 Sequence: [1 2 2] - prediction [3] label: 2 Batch 300 Sequence: [1 2 2] - prediction [2] label: 2 \n",
            "Avg Training Loss: 2.366523434817791 Avg Train Accuracy: 0.2611000003479421\n",
            "\n",
            "Epoch 69\n",
            "Batch 0 Sequence: [1 2 2] - prediction [8] label: 2 Batch 100 Sequence: [1 2 2] - prediction [4] label: 2 Batch 200 Sequence: [5 5 5] - prediction [8] label: 4 Batch 300 Sequence: [2 2 3] - prediction [6] label: 2 \n",
            "Avg Training Loss: 2.406568265557289 Avg Train Accuracy: 0.25869999909773467\n",
            "\n",
            "Final Test Loss: 3.0556222677230833 Final Test Accuracy: 0.13199999928474426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9oATdSjQeyS3",
        "colab_type": "code",
        "outputId": "d7510bb6-d8cb-4bcb-a1e4-bae91690cb68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5050
        }
      },
      "cell_type": "code",
      "source": [
        "#sequence_length = 15\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.01\n",
        "epochs = 70\n",
        "batch_size = 5\n",
        "\n",
        "# length of a single sequence\n",
        "input_seq_len = 15\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 90\n",
        "\n",
        "n_vocab=9\n",
        "\n",
        "\n",
        "RNN_graph = tf.Graph()\n",
        "with RNN_graph.as_default():\n",
        "\n",
        "    # tf Graph input: X = sequences, Y = digits to predict \n",
        "    batchX_placeholder = tf.placeholder(tf.int32, [batch_size, input_seq_len])\n",
        "    batchY_placeholder = tf.placeholder(tf.int32, [batch_size, 1])\n",
        "\n",
        "    # init_state = h0\n",
        "    init_state = tf.Variable(tf.random_normal([batch_size, n_hidden]))\n",
        "\n",
        "    # TODO: RNN output node weights and biases - set the tf.Variables with correct shapes and random_normal initialization\n",
        "    weights = {\n",
        "        'U': tf.Variable(np.random.rand(n_vocab,n_hidden), dtype=tf.float32),\n",
        "        'W': tf.Variable(np.random.rand(n_hidden, n_hidden), dtype=tf.float32),\n",
        "        'V': tf.Variable(np.random.rand(n_hidden, n_vocab), dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    biases = {\n",
        "        'b': tf.Variable(np.zeros((1,n_hidden)), dtype=tf.float32),\n",
        "        'c': tf.Variable(np.zeros((1,n_vocab)), dtype=tf.float32)\n",
        "        }\n",
        "\n",
        "    # TODO: setup graph for the RNN\n",
        "    inputs_series = tf.unstack(batchX_placeholder, axis=1)\n",
        "    labels_series = tf.unstack(batchY_placeholder, axis=1)\n",
        "    labels = tf.one_hot(labels_series,depth=n_vocab)\n",
        "    \n",
        "    h_prev = init_state\n",
        "    states = []\n",
        "    for t in range(input_seq_len):\n",
        "#       input_t = tf.reshape(input_series[t], [batch_size, 1])\n",
        "      x_t = tf.one_hot(inputs_series[t], depth=n_vocab)\n",
        "      a_t = tf.matmul(h_prev,weights['W']) + tf.matmul(x_t,weights['U']) +biases['b']\n",
        "      h_t = tf.tanh(a_t)\n",
        "      states.append(h_t)\n",
        "      h_prev = h_t\n",
        "    \n",
        "    # TODO: network output\n",
        "    \n",
        "    o = tf.matmul(h_t,weights['V'])+biases['c']\n",
        "    predictions = tf.nn.softmax(o)\n",
        "\n",
        "    # class predictions\n",
        "    predictions = tf.argmax(o, axis=1)\n",
        "    predictions = tf.reshape(predictions, [-1, 1])\n",
        "\n",
        "    # TODO: accuracy \n",
        "    correct_prediction = tf.equal(predictions,labels_series)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "    # TODO: loss of the current batch\n",
        "    total_loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=labels,logits=o))\n",
        "    train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(total_loss)\n",
        "\n",
        "\n",
        "\n",
        "X_train, y_train = generate_dataset(sample_count=2000,sample_size=15)\n",
        "X_test, y_test = generate_dataset(sample_count=100,sample_size=15)\n",
        "\n",
        "num_batches = len(X_train) // batch_size\n",
        "\n",
        "# Launch the Session\n",
        "with tf.Session(graph=RNN_graph) as session:\n",
        "\n",
        "    # label shift for loss computation\n",
        "    y_train = y_train - 1\n",
        "    \n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "    session.run(init)\n",
        "\n",
        "    for cur_epoch in range(epochs):\n",
        "\n",
        "        print(\"\\nEpoch {}\".format(cur_epoch))\n",
        "        acc_sum = 0\n",
        "        loss_sum = 0\n",
        "\n",
        "        indices = np.random.permutation(len(X_train))\n",
        "\n",
        "        for cur_batch_count in range(num_batches):\n",
        "\n",
        "            batch_indices = np.array(indices[cur_batch_count:cur_batch_count + batch_size])\n",
        "\n",
        "            x_batch = X_train[batch_indices]\n",
        "            y_batch = y_train[batch_indices]    \n",
        "            \n",
        "            preds, cur_loss, cur_acc, _ = session.run([predictions, total_loss, accuracy, train_step], feed_dict={batchX_placeholder: x_batch, \n",
        "                                                                                    batchY_placeholder: np.reshape(y_batch, [batch_size, 1])\n",
        "                                                                                    })\n",
        "            acc_sum += cur_acc\n",
        "            loss_sum += cur_loss\n",
        "            \n",
        "            # TODO: Implement the printing of the current batch predictions for batch 0, 100, 200, etc.\n",
        "            if cur_batch_count%100 ==0:\n",
        "              print('Batch '+ str(cur_batch_count), end=\"\")\n",
        "              for i in range(batch_size):\n",
        "                s=(' Sequence: {} - prediction {} label: {} ').format(x_batch[i],preds[i],y_batch[i])\n",
        "              print(s,end=\"\")\n",
        "            \n",
        "            \n",
        "        print(\"\\nAvg Training Loss: {} Avg Train Accuracy: {}\".format(loss_sum / num_batches, acc_sum / num_batches))\n",
        "        \n",
        "    # Testing\n",
        "    num_batches = len(X_test) // batch_size\n",
        "    y_test = y_test - 1\n",
        "\n",
        "    acc_sum = 0\n",
        "    loss_sum = 0\n",
        "\n",
        "    for cur_batch_count in range(num_batches):\n",
        "        x_batch = X_test[cur_batch_count:cur_batch_count+batch_size]\n",
        "        y_batch = y_test[cur_batch_count:cur_batch_count+batch_size]            \n",
        "\n",
        "        cur_loss, cur_acc = session.run([total_loss, accuracy], feed_dict={batchX_placeholder: x_batch, \n",
        "                                                                           batchY_placeholder: np.reshape(y_batch, [batch_size, 1])\n",
        "                                                                           })\n",
        "\n",
        "        acc_sum += cur_acc\n",
        "        loss_sum += cur_loss\n",
        "\n",
        "    print(\"\\nFinal Test Loss: {} Final Test Accuracy: {}\".format(loss_sum / num_batches, acc_sum / num_batches))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 0\n",
            "Batch 0 Sequence: [6 6 6 6 6 7 7 7 7 7 7 7 8 8 8] - prediction [6] label: 7 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 200 Sequence: [4 4 4 5 5 5 5 5 6 6 6 6 6 6 7] - prediction [5] label: 6 Batch 300 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [7] label: 6 \n",
            "Avg Training Loss: 2.497075224816799 Avg Train Accuracy: 0.28520000195130707\n",
            "\n",
            "Epoch 1\n",
            "Batch 0 Sequence: [8 9 9 9 9 9 9 9 9 9 1 2 2 3 3] - prediction [5] label: 2 Batch 100 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [5] label: 6 Batch 200 Sequence: [9 9 9 9 9 9 9 9 9 1 2 2 3 3 3] - prediction [5] label: 3 Batch 300 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.3022355288267136 Avg Train Accuracy: 0.3478000047430396\n",
            "\n",
            "Epoch 2\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 100 Sequence: [7 7 7 7 8 8 8 8 8 8 8 8 9 9 9] - prediction [5] label: 8 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [7] label: 5 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.4128373312950133 Avg Train Accuracy: 0.3100000033527613\n",
            "\n",
            "Epoch 3\n",
            "Batch 0 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [5] label: 6 Batch 100 Sequence: [7 7 8 8 8 8 8 8 8 8 9 9 9 9 9] - prediction [7] label: 8 Batch 200 Sequence: [7 7 7 7 8 8 8 8 8 8 8 8 9 9 9] - prediction [8] label: 8 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.3420634347200395 Avg Train Accuracy: 0.3373000045120716\n",
            "\n",
            "Epoch 4\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 200 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 300 Sequence: [9 9 9 9 9 9 9 1 2 2 3 3 3 4 4] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.381461506187916 Avg Train Accuracy: 0.30890000335872175\n",
            "\n",
            "Epoch 5\n",
            "Batch 0 Sequence: [7 7 7 7 8 8 8 8 8 8 8 8 9 9 9] - prediction [5] label: 8 Batch 100 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [6] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 300 Sequence: [6 6 7 7 7 7 7 7 7 8 8 8 8 8 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.3446267008781434 Avg Train Accuracy: 0.33170000366866587\n",
            "\n",
            "Epoch 6\n",
            "Batch 0 Sequence: [8 8 8 8 9 9 9 9 9 9 9 9 9 1 2] - prediction [5] label: 1 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 200 Sequence: [9 9 9 9 9 9 9 1 2 2 3 3 3 4 4] - prediction [5] label: 3 Batch 300 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.3252667781710623 Avg Train Accuracy: 0.3261000033095479\n",
            "\n",
            "Epoch 7\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [3] label: 5 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 200 Sequence: [9 9 1 2 2 3 3 3 4 4 4 4 5 5 5] - prediction [7] label: 4 Batch 300 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.3564230850338936 Avg Train Accuracy: 0.3280000036209822\n",
            "\n",
            "Epoch 8\n",
            "Batch 0 Sequence: [4 4 4 5 5 5 5 5 6 6 6 6 6 6 7] - prediction [5] label: 6 Batch 100 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [8] label: 6 Batch 200 Sequence: [6 7 7 7 7 7 7 7 8 8 8 8 8 8 8] - prediction [5] label: 7 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.4630467353761194 Avg Train Accuracy: 0.31010000290349127\n",
            "\n",
            "Epoch 9\n",
            "Batch 0 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [8] label: 5 Batch 100 Sequence: [6 7 7 7 7 7 7 7 8 8 8 8 8 8 8] - prediction [5] label: 7 Batch 200 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 Batch 300 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.4139649251103403 Avg Train Accuracy: 0.2890000011771917\n",
            "\n",
            "Epoch 10\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 100 Sequence: [6 6 6 6 7 7 7 7 7 7 7 8 8 8 8] - prediction [5] label: 7 Batch 200 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [6] label: 6 Batch 300 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.340278572142124 Avg Train Accuracy: 0.3135000018961728\n",
            "\n",
            "Epoch 11\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 100 Sequence: [6 6 6 6 6 7 7 7 7 7 7 7 8 8 8] - prediction [5] label: 7 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [8] label: 5 \n",
            "Avg Training Loss: 2.402183899283409 Avg Train Accuracy: 0.30740000180900096\n",
            "\n",
            "Epoch 12\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [6] label: 5 Batch 300 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.3421473610401153 Avg Train Accuracy: 0.34680000534281136\n",
            "\n",
            "Epoch 13\n",
            "Batch 0 Sequence: [6 6 6 6 6 6 7 7 7 7 7 7 7 8 8] - prediction [8] label: 7 Batch 100 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [4] label: 3 Batch 200 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [5] label: 6 Batch 300 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [8] label: 6 \n",
            "Avg Training Loss: 2.4662744870781896 Avg Train Accuracy: 0.2882000017538667\n",
            "\n",
            "Epoch 14\n",
            "Batch 0 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [5] label: 5 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.456368969976902 Avg Train Accuracy: 0.294000001642853\n",
            "\n",
            "Epoch 15\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 Batch 100 Sequence: [7 7 8 8 8 8 8 8 8 8 9 9 9 9 9] - prediction [5] label: 8 Batch 200 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 300 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [4] label: 6 \n",
            "Avg Training Loss: 2.344732502400875 Avg Train Accuracy: 0.3246000028960407\n",
            "\n",
            "Epoch 16\n",
            "Batch 0 Sequence: [7 7 7 7 7 7 7 8 8 8 8 8 8 8 8] - prediction [5] label: 8 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 200 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 300 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.3102821147441865 Avg Train Accuracy: 0.33550000390037893\n",
            "\n",
            "Epoch 17\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 8 9 9 9 9 9 9 9 9] - prediction [5] label: 8 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [7] label: 6 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 300 Sequence: [9 9 1 2 2 3 3 3 4 4 4 4 5 5 5] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.3614702744781972 Avg Train Accuracy: 0.3284000040590763\n",
            "\n",
            "Epoch 18\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 9 9 9 9 9 9 9 9 9] - prediction [5] label: 0 Batch 100 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [6] label: 6 Batch 200 Sequence: [8 9 9 9 9 9 9 9 9 9 1 2 2 3 3] - prediction [5] label: 2 Batch 300 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.385583244860172 Avg Train Accuracy: 0.3416000034473836\n",
            "\n",
            "Epoch 19\n",
            "Batch 0 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [6] label: 5 Batch 100 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [8] label: 5 Batch 300 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.394874459803104 Avg Train Accuracy: 0.31300000319257376\n",
            "\n",
            "Epoch 20\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 Batch 100 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [5] label: 5 Batch 200 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 Batch 300 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [6] label: 5 \n",
            "Avg Training Loss: 2.3742851623892784 Avg Train Accuracy: 0.34470000430941583\n",
            "\n",
            "Epoch 21\n",
            "Batch 0 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [5] label: 6 Batch 100 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [6] label: 6 Batch 200 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 300 Sequence: [7 7 7 7 7 7 8 8 8 8 8 8 8 8 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.3228730821609496 Avg Train Accuracy: 0.32290000323206186\n",
            "\n",
            "Epoch 22\n",
            "Batch 0 Sequence: [6 6 6 6 6 7 7 7 7 7 7 7 8 8 8] - prediction [5] label: 7 Batch 100 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [5] label: 7 Batch 200 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 Batch 300 Sequence: [8 8 8 9 9 9 9 9 9 9 9 9 1 2 2] - prediction [5] label: 2 \n",
            "Avg Training Loss: 2.4542409217357637 Avg Train Accuracy: 0.30410000272095206\n",
            "\n",
            "Epoch 23\n",
            "Batch 0 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [8] label: 7 Batch 100 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [6] label: 5 Batch 200 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [8] label: 5 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.3498932415246965 Avg Train Accuracy: 0.3264000028930604\n",
            "\n",
            "Epoch 24\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 100 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 Batch 200 Sequence: [8 8 8 8 9 9 9 9 9 9 9 9 9 1 2] - prediction [5] label: 1 Batch 300 Sequence: [7 7 7 8 8 8 8 8 8 8 8 9 9 9 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.4378694671392442 Avg Train Accuracy: 0.30810000317171216\n",
            "\n",
            "Epoch 25\n",
            "Batch 0 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 300 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.3304189130663873 Avg Train Accuracy: 0.31300000270828604\n",
            "\n",
            "Epoch 26\n",
            "Batch 0 Sequence: [9 9 9 9 1 2 2 3 3 3 4 4 4 4 5] - prediction [5] label: 4 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [7] label: 7 Batch 200 Sequence: [9 9 9 9 9 1 2 2 3 3 3 4 4 4 4] - prediction [5] label: 4 Batch 300 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [6] label: 6 \n",
            "Avg Training Loss: 2.348300144225359 Avg Train Accuracy: 0.3142000026628375\n",
            "\n",
            "Epoch 27\n",
            "Batch 0 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [5] label: 6 Batch 100 Sequence: [9 9 9 1 2 2 3 3 3 4 4 4 4 5 5] - prediction [6] label: 4 Batch 200 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 Batch 300 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [7] label: 7 \n",
            "Avg Training Loss: 2.3289794132113455 Avg Train Accuracy: 0.31910000249743464\n",
            "\n",
            "Epoch 28\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [8] label: 5 Batch 100 Sequence: [7 7 7 7 7 7 8 8 8 8 8 8 8 8 9] - prediction [5] label: 8 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 300 Sequence: [7 7 7 7 7 8 8 8 8 8 8 8 8 9 9] - prediction [7] label: 8 \n",
            "Avg Training Loss: 2.3298366603255274 Avg Train Accuracy: 0.3111000028066337\n",
            "\n",
            "Epoch 29\n",
            "Batch 0 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [8] label: 4 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [8] label: 7 Batch 200 Sequence: [9 9 9 9 9 9 9 9 9 1 2 2 3 3 3] - prediction [5] label: 3 Batch 300 Sequence: [6 6 7 7 7 7 7 7 7 8 8 8 8 8 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.441164885163307 Avg Train Accuracy: 0.3324000035226345\n",
            "\n",
            "Epoch 30\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 Batch 100 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [7] label: 6 Batch 200 Sequence: [8 8 8 8 8 9 9 9 9 9 9 9 9 9 1] - prediction [6] label: 1 Batch 300 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.422856308966875 Avg Train Accuracy: 0.3130000030435622\n",
            "\n",
            "Epoch 31\n",
            "Batch 0 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [5] label: 6 Batch 100 Sequence: [9 9 9 9 9 9 9 1 2 2 3 3 3 4 4] - prediction [5] label: 3 Batch 200 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [8] label: 6 Batch 300 Sequence: [8 8 8 8 8 8 8 8 9 9 9 9 9 9 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.3561134040355682 Avg Train Accuracy: 0.30920000214129684\n",
            "\n",
            "Epoch 32\n",
            "Batch 0 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 200 Sequence: [6 7 7 7 7 7 7 7 8 8 8 8 8 8 8] - prediction [5] label: 7 Batch 300 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.3116454312205317 Avg Train Accuracy: 0.32320000329986215\n",
            "\n",
            "Epoch 33\n",
            "Batch 0 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [5] label: 6 Batch 100 Sequence: [8 9 9 9 9 9 9 9 9 9 1 2 2 3 3] - prediction [8] label: 2 Batch 200 Sequence: [9 9 9 9 9 9 9 9 9 1 2 2 3 3 3] - prediction [5] label: 3 Batch 300 Sequence: [7 7 8 8 8 8 8 8 8 8 9 9 9 9 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.5157505932450293 Avg Train Accuracy: 0.2943000030517578\n",
            "\n",
            "Epoch 34\n",
            "Batch 0 Sequence: [6 6 6 7 7 7 7 7 7 7 8 8 8 8 8] - prediction [6] label: 7 Batch 100 Sequence: [8 8 8 8 8 8 8 9 9 9 9 9 9 9 9] - prediction [4] label: 8 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [7] label: 5 Batch 300 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.342421868443489 Avg Train Accuracy: 0.32310000274330375\n",
            "\n",
            "Epoch 35\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.332255361676216 Avg Train Accuracy: 0.326700003053993\n",
            "\n",
            "Epoch 36\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [7] label: 5 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [8] label: 5 Batch 300 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.3064221155643465 Avg Train Accuracy: 0.3480000040307641\n",
            "\n",
            "Epoch 37\n",
            "Batch 0 Sequence: [9 9 9 9 9 9 9 9 9 1 2 2 3 3 3] - prediction [5] label: 3 Batch 100 Sequence: [6 6 6 6 6 7 7 7 7 7 7 7 8 8 8] - prediction [6] label: 7 Batch 200 Sequence: [8 8 8 8 8 8 9 9 9 9 9 9 9 9 9] - prediction [7] label: 0 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.366090331077576 Avg Train Accuracy: 0.34010000413283703\n",
            "\n",
            "Epoch 38\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 100 Sequence: [6 6 6 7 7 7 7 7 7 7 8 8 8 8 8] - prediction [5] label: 7 Batch 200 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [7] label: 6 Batch 300 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [6] label: 7 \n",
            "Avg Training Loss: 2.361532124876976 Avg Train Accuracy: 0.33790000546723603\n",
            "\n",
            "Epoch 39\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [6] label: 5 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [5] label: 5 Batch 200 Sequence: [8 8 9 9 9 9 9 9 9 9 9 1 2 2 3] - prediction [5] label: 2 Batch 300 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [6] label: 6 \n",
            "Avg Training Loss: 2.2879003313183786 Avg Train Accuracy: 0.3209000023268163\n",
            "\n",
            "Epoch 40\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 300 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.3135563558340073 Avg Train Accuracy: 0.32370000330731274\n",
            "\n",
            "Epoch 41\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 8 8 9 9 9 9 9 9 9] - prediction [5] label: 8 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 200 Sequence: [9 9 9 9 9 9 9 9 1 2 2 3 3 3 4] - prediction [6] label: 3 Batch 300 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.4743359696865084 Avg Train Accuracy: 0.32110000275075434\n",
            "\n",
            "Epoch 42\n",
            "Batch 0 Sequence: [8 8 8 8 8 8 8 8 9 9 9 9 9 9 9] - prediction [5] label: 8 Batch 100 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [7] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 300 Sequence: [8 8 8 8 8 8 8 9 9 9 9 9 9 9 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.4654312613606453 Avg Train Accuracy: 0.2852000018209219\n",
            "\n",
            "Epoch 43\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 100 Sequence: [6 6 6 6 7 7 7 7 7 7 7 8 8 8 8] - prediction [6] label: 7 Batch 200 Sequence: [4 4 4 5 5 5 5 5 6 6 6 6 6 6 7] - prediction [6] label: 6 Batch 300 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.353829782605171 Avg Train Accuracy: 0.31730000192299485\n",
            "\n",
            "Epoch 44\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 100 Sequence: [7 7 8 8 8 8 8 8 8 8 9 9 9 9 9] - prediction [5] label: 8 Batch 200 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [7] label: 6 Batch 300 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [6] label: 4 \n",
            "Avg Training Loss: 2.3692277245223523 Avg Train Accuracy: 0.3350000033155084\n",
            "\n",
            "Epoch 45\n",
            "Batch 0 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [6] label: 6 Batch 100 Sequence: [8 8 8 9 9 9 9 9 9 9 9 9 1 2 2] - prediction [5] label: 2 Batch 200 Sequence: [9 9 9 9 9 9 9 9 1 2 2 3 3 3 4] - prediction [3] label: 3 Batch 300 Sequence: [8 8 9 9 9 9 9 9 9 9 9 1 2 2 3] - prediction [5] label: 2 \n",
            "Avg Training Loss: 2.3101986864209176 Avg Train Accuracy: 0.3074000020697713\n",
            "\n",
            "Epoch 46\n",
            "Batch 0 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 Batch 100 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [6] label: 5 Batch 200 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [8] label: 3 Batch 300 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.457229657322168 Avg Train Accuracy: 0.3041000016592443\n",
            "\n",
            "Epoch 47\n",
            "Batch 0 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [8] label: 7 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [8] label: 5 Batch 200 Sequence: [9 9 9 9 1 2 2 3 3 3 4 4 4 4 5] - prediction [6] label: 4 Batch 300 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 \n",
            "Avg Training Loss: 2.4759142601490023 Avg Train Accuracy: 0.3017000023461878\n",
            "\n",
            "Epoch 48\n",
            "Batch 0 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [6] label: 5 Batch 100 Sequence: [7 7 7 7 7 8 8 8 8 8 8 8 8 9 9] - prediction [5] label: 8 Batch 200 Sequence: [6 6 6 6 7 7 7 7 7 7 7 8 8 8 8] - prediction [5] label: 7 Batch 300 Sequence: [9 9 9 9 1 2 2 3 3 3 4 4 4 4 5] - prediction [5] label: 4 \n",
            "Avg Training Loss: 2.378806802481413 Avg Train Accuracy: 0.3275000044889748\n",
            "\n",
            "Epoch 49\n",
            "Batch 0 Sequence: [6 6 6 6 7 7 7 7 7 7 7 8 8 8 8] - prediction [5] label: 7 Batch 100 Sequence: [6 7 7 7 7 7 7 7 8 8 8 8 8 8 8] - prediction [4] label: 7 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 300 Sequence: [6 6 6 6 6 6 7 7 7 7 7 7 7 8 8] - prediction [6] label: 7 \n",
            "Avg Training Loss: 2.3161179658770563 Avg Train Accuracy: 0.30520000170916317\n",
            "\n",
            "Epoch 50\n",
            "Batch 0 Sequence: [7 7 7 7 7 7 7 8 8 8 8 8 8 8 8] - prediction [8] label: 8 Batch 100 Sequence: [8 8 8 8 8 9 9 9 9 9 9 9 9 9 1] - prediction [5] label: 1 Batch 200 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [5] label: 5 Batch 300 Sequence: [9 9 1 2 2 3 3 3 4 4 4 4 5 5 5] - prediction [7] label: 4 \n",
            "Avg Training Loss: 2.496654151380062 Avg Train Accuracy: 0.3290000043064356\n",
            "\n",
            "Epoch 51\n",
            "Batch 0 Sequence: [6 7 7 7 7 7 7 7 8 8 8 8 8 8 8] - prediction [6] label: 7 Batch 100 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [8] label: 5 Batch 200 Sequence: [6 6 6 6 6 6 7 7 7 7 7 7 7 8 8] - prediction [5] label: 7 Batch 300 Sequence: [4 4 5 5 5 5 5 6 6 6 6 6 6 7 7] - prediction [6] label: 6 \n",
            "Avg Training Loss: 2.375164667069912 Avg Train Accuracy: 0.30590000215917823\n",
            "\n",
            "Epoch 52\n",
            "Batch 0 Sequence: [6 6 6 7 7 7 7 7 7 7 8 8 8 8 8] - prediction [5] label: 7 Batch 100 Sequence: [8 9 9 9 9 9 9 9 9 9 1 2 2 3 3] - prediction [4] label: 2 Batch 200 Sequence: [8 8 9 9 9 9 9 9 9 9 9 1 2 2 3] - prediction [7] label: 2 Batch 300 Sequence: [7 7 7 7 8 8 8 8 8 8 8 8 9 9 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.3205688011646273 Avg Train Accuracy: 0.3275000023469329\n",
            "\n",
            "Epoch 53\n",
            "Batch 0 Sequence: [9 9 9 9 1 2 2 3 3 3 4 4 4 4 5] - prediction [5] label: 4 Batch 100 Sequence: [4 5 5 5 5 5 6 6 6 6 6 6 7 7 7] - prediction [6] label: 6 Batch 200 Sequence: [9 9 9 9 9 9 9 1 2 2 3 3 3 4 4] - prediction [5] label: 3 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.4037712252140047 Avg Train Accuracy: 0.29710000164806843\n",
            "\n",
            "Epoch 54\n",
            "Batch 0 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [8] label: 7 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 300 Sequence: [3 3 4 4 4 4 5 5 5 5 5 6 6 6 6] - prediction [7] label: 5 \n",
            "Avg Training Loss: 2.322432633638382 Avg Train Accuracy: 0.3486000041849911\n",
            "\n",
            "Epoch 55\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 100 Sequence: [6 6 6 6 6 6 7 7 7 7 7 7 7 8 8] - prediction [5] label: 7 Batch 200 Sequence: [8 9 9 9 9 9 9 9 9 9 1 2 2 3 3] - prediction [5] label: 2 Batch 300 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [6] label: 5 \n",
            "Avg Training Loss: 2.4550281718373297 Avg Train Accuracy: 0.29480000225827097\n",
            "\n",
            "Epoch 56\n",
            "Batch 0 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [8] label: 6 Batch 100 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [5] label: 7 Batch 200 Sequence: [7 7 8 8 8 8 8 8 8 8 9 9 9 9 9] - prediction [8] label: 8 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [7] label: 5 \n",
            "Avg Training Loss: 2.396114656031132 Avg Train Accuracy: 0.2982000010833144\n",
            "\n",
            "Epoch 57\n",
            "Batch 0 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 Batch 100 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 Batch 200 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [6] label: 5 Batch 300 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.4288931173086166 Avg Train Accuracy: 0.3221000035665929\n",
            "\n",
            "Epoch 58\n",
            "Batch 0 Sequence: [8 9 9 9 9 9 9 9 9 9 1 2 2 3 3] - prediction [6] label: 2 Batch 100 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [6] label: 5 Batch 200 Sequence: [7 7 7 7 7 7 8 8 8 8 8 8 8 8 9] - prediction [5] label: 8 Batch 300 Sequence: [7 7 7 7 7 7 7 8 8 8 8 8 8 8 8] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.393842805624008 Avg Train Accuracy: 0.32040000334382057\n",
            "\n",
            "Epoch 59\n",
            "Batch 0 Sequence: [3 4 4 4 4 5 5 5 5 5 6 6 6 6 6] - prediction [5] label: 5 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 200 Sequence: [6 6 6 6 6 6 7 7 7 7 7 7 7 8 8] - prediction [5] label: 7 Batch 300 Sequence: [7 7 7 7 7 7 7 8 8 8 8 8 8 8 8] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.3589280049502848 Avg Train Accuracy: 0.3345000044628978\n",
            "\n",
            "Epoch 60\n",
            "Batch 0 Sequence: [6 6 6 7 7 7 7 7 7 7 8 8 8 8 8] - prediction [6] label: 7 Batch 100 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [5] label: 6 Batch 200 Sequence: [9 9 9 9 9 9 1 2 2 3 3 3 4 4 4] - prediction [5] label: 3 Batch 300 Sequence: [7 7 7 7 8 8 8 8 8 8 8 8 9 9 9] - prediction [5] label: 8 \n",
            "Avg Training Loss: 2.360453305244446 Avg Train Accuracy: 0.29970000188797713\n",
            "\n",
            "Epoch 61\n",
            "Batch 0 Sequence: [9 1 2 2 3 3 3 4 4 4 4 5 5 5 5] - prediction [5] label: 4 Batch 100 Sequence: [8 8 8 8 8 8 8 9 9 9 9 9 9 9 9] - prediction [5] label: 8 Batch 200 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [8] label: 5 Batch 300 Sequence: [2 3 3 3 4 4 4 4 5 5 5 5 5 6 6] - prediction [3] label: 5 \n",
            "Avg Training Loss: 2.3552284748852252 Avg Train Accuracy: 0.3193000026606023\n",
            "\n",
            "Epoch 62\n",
            "Batch 0 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 100 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [6] label: 7 Batch 200 Sequence: [8 8 8 8 8 8 8 9 9 9 9 9 9 9 9] - prediction [5] label: 8 Batch 300 Sequence: [6 6 6 6 6 7 7 7 7 7 7 7 8 8 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.4043355913460256 Avg Train Accuracy: 0.3242000037804246\n",
            "\n",
            "Epoch 63\n",
            "Batch 0 Sequence: [7 7 7 8 8 8 8 8 8 8 8 9 9 9 9] - prediction [8] label: 8 Batch 100 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [5] label: 5 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [8] label: 5 Batch 300 Sequence: [8 8 8 9 9 9 9 9 9 9 9 9 1 2 2] - prediction [5] label: 2 \n",
            "Avg Training Loss: 2.3265475019812585 Avg Train Accuracy: 0.31480000337585806\n",
            "\n",
            "Epoch 64\n",
            "Batch 0 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [8] label: 5 Batch 200 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 300 Sequence: [8 8 8 8 8 9 9 9 9 9 9 9 9 9 1] - prediction [5] label: 1 \n",
            "Avg Training Loss: 2.3530572633445264 Avg Train Accuracy: 0.33860000398010015\n",
            "\n",
            "Epoch 65\n",
            "Batch 0 Sequence: [4 4 4 4 5 5 5 5 5 6 6 6 6 6 6] - prediction [6] label: 6 Batch 100 Sequence: [5 5 5 6 6 6 6 6 6 7 7 7 7 7 7] - prediction [8] label: 6 Batch 200 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 300 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 \n",
            "Avg Training Loss: 2.3941778703033925 Avg Train Accuracy: 0.3179000025056303\n",
            "\n",
            "Epoch 66\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 100 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 200 Sequence: [8 8 8 8 8 8 8 9 9 9 9 9 9 9 9] - prediction [5] label: 8 Batch 300 Sequence: [8 8 9 9 9 9 9 9 9 9 9 1 2 2 3] - prediction [5] label: 2 \n",
            "Avg Training Loss: 2.4079915039241313 Avg Train Accuracy: 0.33090000381693246\n",
            "\n",
            "Epoch 67\n",
            "Batch 0 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 200 Sequence: [5 5 6 6 6 6 6 6 7 7 7 7 7 7 7] - prediction [5] label: 7 Batch 300 Sequence: [6 6 7 7 7 7 7 7 7 8 8 8 8 8 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.372860922217369 Avg Train Accuracy: 0.3411000041477382\n",
            "\n",
            "Epoch 68\n",
            "Batch 0 Sequence: [4 4 4 5 5 5 5 5 6 6 6 6 6 6 7] - prediction [5] label: 6 Batch 100 Sequence: [5 5 5 5 5 6 6 6 6 6 6 7 7 7 7] - prediction [5] label: 6 Batch 200 Sequence: [1 2 2 3 3 3 4 4 4 4 5 5 5 5 5] - prediction [5] label: 5 Batch 300 Sequence: [5 5 5 5 6 6 6 6 6 6 7 7 7 7 7] - prediction [5] label: 6 \n",
            "Avg Training Loss: 2.383907292485237 Avg Train Accuracy: 0.32630000276491045\n",
            "\n",
            "Epoch 69\n",
            "Batch 0 Sequence: [2 2 3 3 3 4 4 4 4 5 5 5 5 5 6] - prediction [5] label: 5 Batch 100 Sequence: [9 9 9 9 9 9 9 9 9 1 2 2 3 3 3] - prediction [6] label: 3 Batch 200 Sequence: [3 3 3 4 4 4 4 5 5 5 5 5 6 6 6] - prediction [4] label: 5 Batch 300 Sequence: [5 6 6 6 6 6 6 7 7 7 7 7 7 7 8] - prediction [5] label: 7 \n",
            "Avg Training Loss: 2.356833557933569 Avg Train Accuracy: 0.33770000336691736\n",
            "\n",
            "Final Test Loss: 1.6213843882083894 Final Test Accuracy: 0.41000001057982444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z60jclBhZDms",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $2$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "ger_LgHgZDmu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3. Language Modelling using a LSTM$~$ (10 points)\n",
        "Language Modelling describes a task similiar to 2. where a sequence of data is given and the subsequent element should get predicted. Hereby, the input sequence is a sequence of words from a natural language sentence and the model should predict the next upcomming word like in an auto correction system. \n",
        "\n",
        "![title](http://ofir.io/images/lm/keyboard.png)\n",
        "\n",
        "For the model setup, we use the implementation of an RNN cell as well as of an LSTM cell by tensorflow."
      ]
    },
    {
      "metadata": {
        "id": "HgWRLCdJZDmv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.1 Data Preparation\n",
        "\n",
        "For this task, our dataset (= corpus) is a small text from the tale **\"Androcles\"** by Aesop you can find in \"train.txt\".\n",
        "\n",
        "A data sample should consist of a sequence of integer word IDs, representing a single word each. The one-hot encoding of the subsequent word which should be predicted, constitues the respecitve label. \n",
        "\n",
        "One-hot encoding of words requires a mapping between words and word IDs. If n different words appear in the corpus, the encoding of a single word has shape (n, 1).\n",
        "\n",
        "Fill in the `#TODO` sections to read the corpus, setup a vocabulary and generate one-hot encoded word sequences with respective label. (**3 points**)"
      ]
    },
    {
      "metadata": {
        "id": "nauu00DWZDnI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def setup_vocab(word_list):\n",
        "    \"\"\"Reads a string list and creates word wise dictionaries by assigning each word a unique id    \n",
        "    \"\"\"\n",
        "    # TODO: create dict with id-word mapping for a list of words\n",
        "    # so that e.g.: id_word_dict[25] = \"dog\"\n",
        "    word_list=list(set(word_list))\n",
        "    \n",
        "    id_word_dict = {i : word_list[i] for i in range(0,len(word_list))}\n",
        "    \n",
        "    \n",
        "   \n",
        "    \n",
        "    # TODO: create dict with word-id mapping for a list of words\n",
        "    # so that e.g.: word_id_dict[\"dog\"] = 25\n",
        "    word_id_dict = {word_list[i] : i for i in range(0,len(word_list))}\n",
        "   \n",
        "    \n",
        "    \n",
        "    return id_word_dict, word_id_dict\n",
        "\n",
        "\n",
        "\n",
        "def word_2_onehot(vocab, input_word):\n",
        "    \n",
        "    # TODO: implement this function returning the one-hot encoding (float array) of the word 'input_word'\n",
        "    iwlist = [0]* len(vocab)\n",
        "    idx =  vocab[input_word]\n",
        "    iwlist[idx] = 1\n",
        "    label_one_hot = iwlist\n",
        "   \n",
        "    \n",
        "\n",
        "    return label_one_hot\n",
        "  \n",
        "\n",
        "\n",
        "def onehot_2_word(vocab, encoding):\n",
        "    \n",
        "    # TODO: implement this function returning the word string from a one-hot encoding\n",
        "    word_decoded = vocab[np.argmax(encoding)]\n",
        "   \n",
        "    return word_decoded\n",
        "\n",
        "\n",
        "def prepare_text(filepath=\"corpus.txt\"):\n",
        "    \"\"\"Reads a text file, removes whitespaces and returns the text as string list\n",
        "    \"\"\"\n",
        "\n",
        "    # read lines\n",
        "    with open(filepath) as f:\n",
        "        content = f.readlines()\n",
        "\n",
        "    # strip lines\n",
        "    content = [x.strip() for x in content]\n",
        "\n",
        "    # split lines into single word lists\n",
        "    content = [content[i].split() for i in range(len(content))]\n",
        "    \n",
        "    # remove non-alphabetics and make lowercase\n",
        "    content = [re.sub('[^A-Za-z]', '', item.lower()) for sublist in content for item in sublist]\n",
        "\n",
        "    # filter out empry strings\n",
        "    content = list(filter(None, content))\n",
        "\n",
        "    return np.array(content)\n",
        "        \n",
        "def prepare_sequences(word_list, vocab, seq_len):\n",
        "    \"\"\"\n",
        "    Samples word sequences from word_list and returns sequences of size seq_len and one-hot encoded word successor word\n",
        "    \"\"\"\n",
        "\n",
        "    samples = []\n",
        "    labels = []\n",
        "    \n",
        "    for start_index in range(len(word_list) - seq_len):\n",
        "        cur_sequence = []\n",
        "        for offset in range(seq_len):\n",
        "            \n",
        "            # sequence of word-ids\n",
        "            word = word_list[start_index + offset]\n",
        "            word_id = vocab[word]\n",
        "            cur_sequence.append(word_id)\n",
        "            \n",
        "        # word-id encoded samples\n",
        "        cur_sequence = np.reshape(np.array(cur_sequence), [seq_len, 1])\n",
        "        samples.append(cur_sequence)\n",
        "        \n",
        "        # one hot encoded label data\n",
        "        word_label = word_list[start_index + seq_len]\n",
        "        label_one_hot =  word_2_onehot(vocab, word_label)\n",
        "        labels.append(label_one_hot)\n",
        "        \n",
        "    return np.array(samples), np.array(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JHIPfoRmZDnQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $3$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "_3pvCzX-ZDnW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.2 Model setup and Training\n",
        "\n",
        "In the following, the complete implementation of RNN is given.\n",
        "\n",
        "Extend the code below at `#TODO`, so that after `display_step` iterations, the function should **print** the currently considered sentence part with the model prediction and the ground truth word like this:\n",
        "\n",
        "`Iteration 9500, Average Loss: 0.348980 Average Accuracy: 93.00%\n",
        "sentence: bound up the paw of the - prediction: lion true word: lion`\n",
        "\n",
        "_(The training of the model with 10000 iterations should not take longer than 20min. For debugging, you can reduce the number)_\n",
        "\n",
        "(**2 points**)"
      ]
    },
    {
      "metadata": {
        "id": "qX-4LPKyRVoG",
        "colab_type": "code",
        "outputId": "92d606bc-7e6d-4665-9026-5c74aab38b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1075
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "path='/content/gdrive/My Drive/'\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-143e28d935b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/gdrive/My Drive/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m       \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msendcontrol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'z'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m   \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Stopped'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "Wvh3xOPAVwgs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 6\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0Hz_QZgMZDng",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RNN\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "        rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jjoNjNnKJdxh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#LSTM\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "#         rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qY7qrbH7ZDnn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $2$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "kfMDv_T7ZDnp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3.3 RNN vs. LSTM\n",
        "\n",
        "a) The sequence length used for prediction in the above code is specified by `n_input`; change `n_inputs` to 1, 3, 30 and report the training accuracies. After computing the values, replace the RNN cell with an LSTM cell (uncomment the line!) and repeat the procedure (in the end you should have 6 accuracy values in total). What trends do you observe with the training accuracies when the sequence length is varied for both models?  (**3 points**)\n",
        "\n",
        "`n_input`      RNN     LSTM\n",
        "---------------------------------------\n",
        "    1       0.026    0.092\n",
        "    3       0.054    0.279\n",
        "    30      0.077    0.865\n",
        "\n",
        "Overall, the LSTM performs better than the RNN for all sequence lengths. While increasing the sequence length improves the performance of both models, the improvement in the LSTM is much higher compared to the RNN. This means that when more context is available for training, the LSTM is able to learn more from that data. \n",
        "\n",
        "b) Which model do you think learns better than the other? Briefly explain your answer. (**1 point**)\n",
        "\n",
        "The LSTM learns better than the RNN. This can be attributed to the model design because while the RNN tries to remember everything (i.e., includes input from all previous time steps in its representation) the LSTM has the ability to 'forget' some of that can only include parts of the sequence that are important for prediction.\n",
        "\n",
        "c) Do you expect the model with higher training accuracy to generalize well? Why? Why not? (**1 point**)\n",
        "\n",
        "If the difference in training accuracy is significantly large, the model with the higher accuracy will perform better on the test set. For example, the RNN and LSTM models have a difference of 78.8% for sequence length 30. So the LSTM will definitely perform better on new, unseen data. However if the difference in the training accuracy of the models is less, then we cannot guarantee the generalisation performance. Infact we can expect the model with higher training accuracy to perform worse because of overfitting on the training data. "
      ]
    },
    {
      "metadata": {
        "id": "Me3WLfuYTcju",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#for LSTM\n",
        "#n_input = 1\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 1\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "#         rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ie-q46ANj41s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For LSTM\n",
        "#n_input = 3\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 3\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "#         rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DwAECZQ_j4Ux",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#For LSTM\n",
        "\n",
        "#n_input = 30\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 30\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "#         rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pj_bpdKSzVSl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RNN \n",
        "\n",
        "#n_input = 1\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 1\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)\n",
        "\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "        rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lLNXM8QwzVJO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RNN \n",
        "\n",
        "#n_input = 3\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 3\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)\n",
        "\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "        rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y3Mhdu-fzU-k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#RNN \n",
        "\n",
        "#n_input = 30\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_iters = 10000\n",
        "display_step = 100\n",
        "n_input = 30\n",
        "\n",
        "text_data = prepare_text(path+\"train.txt\")\n",
        "\n",
        "id_word_dict, word_id_dict = setup_vocab(text_data)\n",
        "\n",
        "samples, labels = prepare_sequences(text_data, word_id_dict, seq_len=n_input)\n",
        "\n",
        "vocab_size = len(word_id_dict)\n",
        "\n",
        "\n",
        "# number of units in RNN cell\n",
        "n_hidden = 512\n",
        "\n",
        "with tf.Graph().as_default():\n",
        "    # tf Graph input\n",
        "    x = tf.placeholder(\"float\", [None, n_input, 1])\n",
        "    y = tf.placeholder(\"float\", [None, vocab_size])\n",
        "\n",
        "    # RNN output node weights and biases\n",
        "    weights = {\n",
        "        'out': tf.Variable(tf.random_normal([n_hidden, vocab_size]))\n",
        "    }\n",
        "    biases = {\n",
        "        'out': tf.Variable(tf.random_normal([vocab_size]))\n",
        "    }\n",
        "\n",
        "    def RNN(x, weights, biases):\n",
        "\n",
        "        # reshape to [1, n_input]\n",
        "        x = tf.reshape(x, [-1, n_input])\n",
        "\n",
        "        # Generate a n_input-element sequence of inputs\n",
        "        x = tf.split(x,n_input,1)\n",
        "\n",
        "        # TODO replace the following layer with a Vanilla RNN tf.contrib.rnn call        \n",
        "        rnn_cell = rnn.BasicRNNCell(n_hidden)\n",
        "        # rnn_cell = rnn.BasicLSTMCell(n_hidden)\n",
        "\n",
        "        # generate prediction\n",
        "        outputs, states = rnn.static_rnn(rnn_cell, x, dtype=tf.float32)\n",
        "\n",
        "        # there are n_input outputs but\n",
        "        # we only want the last output\n",
        "        return tf.matmul(outputs[-1], weights['out']) + biases['out']\n",
        "\n",
        "\n",
        "    pred = RNN(x, weights, biases)\n",
        "\n",
        "    # Loss and optimizer\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))\n",
        "    optimizer = tf.train.RMSPropOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "\n",
        "    # Model evaluation\n",
        "    correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
        "\n",
        "    # Initializing the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Launch the Session\n",
        "    with tf.Session() as session:\n",
        "        session.run(init)\n",
        "        step = 0\n",
        "        offset = random.randint(0,n_input+1)\n",
        "        end_offset = n_input + 1\n",
        "        acc_total = 0\n",
        "        loss_total = 0\n",
        "\n",
        "        while step < training_iters:\n",
        "            \n",
        "            # Generate a minibatch. Add some randomness on selection process.\n",
        "            if offset > (len(samples)-end_offset):\n",
        "                offset = random.randint(0, n_input+1)\n",
        "\n",
        "            symbols_in_keys = samples[offset]\n",
        "            symbols_in_keys = np.reshape(np.array(symbols_in_keys), [-1, n_input, 1])\n",
        "\n",
        "            symbols_out_onehot = labels[offset] \n",
        "            symbols_out_onehot = np.reshape(symbols_out_onehot,[1,-1])\n",
        "\n",
        "            _, acc, loss, onehot_pred = session.run([optimizer, accuracy, cost, pred], \\\n",
        "                                                    feed_dict={x: symbols_in_keys, y: symbols_out_onehot})\n",
        "            loss_total += loss\n",
        "            acc_total += acc\n",
        "            \n",
        "            #TODO: after every 'display_step' steps, print the current information as stated in the exercise\n",
        "            if step%display_step==0:\n",
        "              in_seq= ' '.join([id_word_dict[i[0]] for i in symbols_in_keys[0]])\n",
        "              y_hat= id_word_dict[np.argmax(onehot_pred)]\n",
        "              y_real= id_word_dict[np.argmax(symbols_out_onehot)]\n",
        "              s=('Iteration {}, Average Loss: {:.6f} Average Accuracy: {:.2f}% sentence: {} - prediction: {} true word: {}').format(step,loss_total/step,acc_total*100/step,in_seq,y_hat,y_real)\n",
        "              print(s)\n",
        "                            \n",
        "            step += 1\n",
        "            offset += (n_input+1)\n",
        "        print(\"Training Finished!\")\n",
        "        print(\"Computing total accuracy...\")\n",
        "        acc = session.run([accuracy], feed_dict={x: samples, y: labels})\n",
        "\n",
        "        print(\"\\nTotal Accuracy: \" + str(acc[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eBH8Zw8mlPED",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8XhRBGIKZDnq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---\n",
        "**Points:** $0.0$ of $5$\n",
        "**Comments:** None\n",
        "\n",
        "---"
      ]
    },
    {
      "metadata": {
        "id": "67RyFNKoZDnv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "B6A6K5NkZDn0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Submission instructions\n",
        "You should provide a single Jupyter notebook (.ipynb file) as the solution. Put the names and student ids of your team members below. **Make sure to submit only 1 solution to only 1 tutor.**\n",
        "\n",
        "- Khushboo Mehra, 2576512\n",
        "- Soumya Sahoo, 2576610\n",
        "- Vinit Hegiste, 2576578"
      ]
    },
    {
      "metadata": {
        "id": "8-lsgSq9ZDn_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Points: 0.0 of 30.0 points"
      ]
    }
  ]
}